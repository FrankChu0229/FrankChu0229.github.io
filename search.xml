<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[scrapy-summary]]></title>
    <url>%2F2018%2F06%2F08%2Fscrapy-summary%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[beautifulsoup-summary]]></title>
    <url>%2F2018%2F06%2F08%2Fbeautifulsoup-summary%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Pandas Summary]]></title>
    <url>%2F2018%2F06%2F06%2Fpandas-summary%2F</url>
    <content type="text"><![CDATA[Pandas DemoPandas 是基于numpy构建的，如果用python中的list和dict来做比较，numpy可以看作是list， pandas为dict。 Pandas BasicSeries and DataFrame123456789101112131415161718192021222324252627282930313233343536import pandas as pdimport numpy as npseries = pd.Series([0,1,2,3,4,np.nan], index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;])print(s)print(s[0])dates = pd.date_range(&apos;20180101&apos;, periods=6)print(dates)data_frame = pd.DataFrame(np.random.randn(6,4), index=dates, columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])print(data_frame)print(data_frame[&apos;b&apos;])df = pd.DataFrame(np.random.random((6,4)))print(df)print(df.dtypes)df1 = pd.DataFrame( &#123; &apos;a&apos;: 1., &apos;b&apos;: pd.Categorical([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;]), &apos;c&apos;: pd.Series(1, index=list(range(4))), &apos;d&apos;: pd.Timestamp(&apos;20180101&apos;), &apos;e&apos;: np.array([4]*4) &#125;)print(df1)print(df1.index)print(df1.columns)print(df1.values)print(df1.transpose)print(df1.sort_index(axis=1, ascending=False))print(df1.sort_values(by=&apos;b&apos;)) pandas choose data:12345678910111213141516171819202122232425262728293031import pandas as pdimport numpy as npdates = pd.date_range(&apos;20180101&apos;, periods=6)df = pd.DataFrame(np.random.random((6,4)), index=dates, columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])print(df)## 多行多列print(df[&apos;a&apos;])print(df.a)print(df[0:2])print(df[&apos;2018-01-02&apos;: &apos;2018-01-03&apos;])## 使用loc iloc 和ix## loc use index nameprint(&apos;df loc values&apos;, df.loc[&apos;2018-01-02&apos;])print(&apos;df loc values&apos;, df.loc[&apos;2018-01-02&apos;, &apos;a&apos;])print(&apos;df loc values&apos;, df.loc[:,[&apos;a&apos;,&apos;b&apos;]])## iloc use index:0,1,2,3print(&apos;df iloc values&apos;, df.iloc[0,1])print(&apos;df iloc values&apos;, df.iloc[0])print(&apos;df iloc values&apos;, df.iloc[0, 1:3])print(&apos;df iloc values&apos;, df.iloc[0:2, 1])print(&apos;df iloc values&apos;, df.iloc[0:2, 1:3])print(&apos;df iloc values&apos;, df.iloc[[1,2,3], 1:3])print(&apos;df ix values:&apos;, df.ix[0:1, [&apos;a&apos;, &apos;d&apos;]])print(&apos;df comparision values are:&apos;, df[df.a &gt; df.b]) pandas set value1234567891011121314151617181920212223242526272829303132import pandas as pdimport numpy as npdates = pd.date_range(&apos;20180101&apos;, periods=6)df = pd.DataFrame(np.random.random((6,4)), index=dates, columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])## 行列 loc iloc andprint(df)df[&apos;a&apos;] = 0print(df)df.b = 0print(df)## 有: 时 才是对行操作df[&apos;2018-01-01&apos;: &apos;2018-01-02&apos;] = np.nanprint(df)df.iloc[0,1] = np.nanprint(df)df[&apos;e&apos;] = np.nanprint(df)df.b[df.b &gt; -0.2] = 88print(df)## pandas nan processprint(df.dropna(axis=0, how=&apos;any&apos;)) ## axis=0 row, axis = 1 columnprint(df.fillna(value=0))print(df.isnull()) pandas read and write file:pandas can read and write csv, json, excel, html, pickle etc.1234567import pandas as pdpd.read_csv(&apos;student.csv&apos;)pd.read_excel(&apos;a.excel&apos;)##pd.to_pickle(&apos;student.pickle&apos;) Pandas Concat12345678910111213141516171819202122232425262728import pandas as pdimport numpy as npdf1 = pd.DataFrame(np.ones((3,4))*0, columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])df2 = pd.DataFrame(np.ones((3,4))*1, columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])df3 = pd.DataFrame(np.ones((3,4))*2, columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])print(pd.concat([df1, df2, df3], axis=0)) # 0 在row上concatprint(pd.concat([df1, df2, df3], axis=1)) # 1 在column上concatprint(pd.concat([df1, df2, df3], axis=0, ignore_index=True)) # ignore index: reindexdf4 = pd.DataFrame(np.ones((3,4))*2, columns=[ &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;])print(pd.concat([df1, df4], axis=0, join=&apos;outer&apos;))print(pd.concat([df1, df4], axis=0, join=&apos;inner&apos;))df5 = pd.DataFrame(np.ones((3,4))*2, columns=[ &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index=[2,3,4])print(pd.concat([df1, df5], axis=1))print(pd.concat([df1, df5], axis=1, join_axes=[df1.index]))print(pd.concat([df1, df5], axis=1, join_axes=[df5.index]))## append 只能在行级别增加，即纵向增加print(df1.append(df2))print(df1.append([df2, df3]))print(df1.append([df2, df3], ignore_index=True)) pandas merge: 合并有相同column的pandas dataframe等123456789101112131415import pandas as pdimport numpy as npa = pd.DataFrame(&#123; &apos;a&apos;: [&apos;a0&apos;, &apos;a1&apos;, &apos;a2&apos;], &apos;b&apos;: [&apos;b0&apos;, &apos;b1&apos;, &apos;b2&apos;]&#125;)b = pd.DataFrame(&#123; &apos;b&apos; : [&apos;b0&apos;, &apos;b1&apos;, &apos;b3&apos;]&#125;)print(pd.merge(a, b, on=&apos;b&apos;))print(pd.merge(a, b, on=&apos;b&apos;, how=&apos;outer&apos;)) Pandas Plot12345678910111213141516%matplotlib inlineimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltseries = pd.Series(np.random.randn(1000))print(series)print(series.cumsum())series.plot()plt.show()df = pd.DataFrame(np.random.randn(1000,4), columns=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])df.plot()plt.show() Reference-mofan-python-pandas-tutorial]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>dl</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy Summary]]></title>
    <url>%2F2018%2F06%2F06%2Fnumpy-summary%2F</url>
    <content type="text"><![CDATA[Numpy 是一个高性能的多维数组计算库，常被用在科学计算中。 Numpy Fields and Basic OperationsNumpy basic fields: ndim, size and shape. 12345678910111213141516171819202122232425262728293031323334353637## Numpy basics: fields and matrix operation.import numpy as nparray = np.array([[1,2,3], [4,5,6], [7,8,9]])a = np.array([1,2,3])print(a.ndim)print(array)print(array[0][2])print(&apos;dim is&apos;, array.ndim)print(&apos;shape is&apos;, array.shape)print(&apos;size is&apos;, array.size)## dtype dtype_array = np.array([1,2,3])print(dtype_array.dtype)dtype_array1 = np.array([1,2,3,4,5], dtype=np.float)print(dtype_array1.dtype)## matrix operationmatrix_a = np.array([[1,2,3], [4,5,6]])print(matrix_a)matrix_zeros = np.zeros((2,3))print(matrix_zeros)matrix_ones = np.ones((2,3), dtype=int)print(matrix_ones)matrix_empty = np.empty((2,3)) ## create values that are close to zero.print(matrix_empty)matrix_arange = np.arange(1,50,2)print(matrix_arange)matrix_reshape = matrix_arange.reshape((5,5))print(matrix_reshape)## linspace: to create 20 elememts between 1 and 10 matrix_linspace = np.linspace(1,10,20)print(matrix_linspace) Numpy Array Computation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import numpy as np## numpy calculation:matrix_a = np.array([[1,2,3], [4,5,6], [7,8,9]])matrix_b = np.arange(10, 19).reshape((3,3))print(matrix_a)print(matrix_b)print(matrix_a + matrix_b)print(matrix_a - matrix_b)print(matrix_a * matrix_b) ## point-wise multiply.print(&quot;a*b for matrix multiply calculation is:&quot;, np.dot(matrix_a, matrix_b)) ## normal matrix multiplyprint(&quot;a*b for matrix multiply calculation is:&quot;, matrix_a.dot(matrix_b)) ## normal matrix multiplyprint(np.sin(matrix_a))print(matrix_b &lt; 15)print(matrix_b**2)matrix_random = np.random.random((3,4))print(matrix_random)## Operation over the whole matrix.print(np.sum(matrix_random))print(np.min(matrix_random))print(np.max(matrix_random))## Operation over the single row or column， 0 for column, 1 for row.print(&apos;row operation results:&apos;, np.max(matrix_random, axis=0))print(&apos;column operation results:&apos;, np.max(matrix_random, axis=1))## numpy mateix operation 2import numpy as npmatrix = np.arange(12, 0, -1).reshape((3,4))print(matrix)print(matrix.argmax())print(matrix.argmin())print(np.argmax(matrix))print(matrix.mean())print(matrix.cumsum()) ## cumulutive sumprint(np.diff(matrix)) ## 后一项减去前一项print(np.nonzero(matrix))print(matrix)print(np.sort(matrix, axis=0))print(np.sort(matrix, axis=1))print(matrix.T)print(np.transpose(matrix))print(np.clip(matrix, 5,9)) Numpy 索引12345678910111213141516171819202122## numpy 索引import numpy as npmatrix = np.arange(12).reshape((3,4))print(matrix)print(matrix[0][1])print(matrix[0,1])print(matrix[0][1:3])print(matrix[0, 1:3])for row in matrix: print(row) for column in matrix.T: print(column)print(matrix.flatten()) ## listprint(list(matrix.flat)) ## 迭代器 Numpy Array 合并 &amp;&amp; 分割1234567891011121314151617181920212223242526272829303132333435363738394041## Numpy array 合并a = np.array([[1,2,3],[4,5,6]])b = np.array([[4,5,6],[1,2,3]])c = np.vstack((a,b))print(c)d = np.hstack((a, b))print(d)tmp = np.array([1,2,3])print(tmp.shape)print(tmp[:, np.newaxis].shape)print(tmp[np.newaxis, :].shape)print(np.hstack((a,b)))print(np.concatenate((a, b), axis=1))print(np.vstack((a,b)))print(np.concatenate((a,b), axis=0))## numpy array 分割## 等分分割print(c)c_split = np.split(c, 2, axis=0)print(np.vsplit(c, 2))print(c_split)print(d)d_split = np.split(d, 2, axis=1)print(np.hsplit(d, 2))print(d_split)## 不等分分割not_split = np.array_split(c, 3, axis=0)print(not_split) Numpy Copy and Deep Copy1234567891011121314151617## numpy copy and deep copya = np.array([[1,2,3]])print(a)b = aprint(b is a)a[0][1] = 5print(a)print(b)## deep copyc = a.copy()print(a)print(c)a[0][1] = 8print(a)print(c) Reference reference-mofan-numpy-tutorial]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>dl</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras Summary]]></title>
    <url>%2F2018%2F06%2F06%2Fkeras-summary%2F</url>
    <content type="text"></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>keras</tag>
        <tag>dl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Summary]]></title>
    <url>%2F2018%2F06%2F04%2Fdocker-summary%2F</url>
    <content type="text"><![CDATA[Docker build image and push to remote registry To add Dockerfile run docker build -t image_name . to build image run docker image ls to list all images run docker login docker.XXX.com to login the docker registry run docker tag image_name username/repository:tag to tag the image run docker push username/repository:tag to push the image to the remote repository. Reference Docker Tutorial]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Cookbook String and Text]]></title>
    <url>%2F2018%2F06%2F04%2Fpython-cookbook-str-text%2F</url>
    <content type="text"></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>python</tag>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Dependency Management]]></title>
    <url>%2F2018%2F05%2F30%2Fpython-dependency-management%2F</url>
    <content type="text"><![CDATA[Requirements pip install -r requirements.txt to install all dependency in requirements. pip freeze &gt; requirements.txt to export all depenedncies to requirements.txt]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>coding</tag>
        <tag>dependency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Underline Usage]]></title>
    <url>%2F2018%2F05%2F28%2Fpython-underline%2F</url>
    <content type="text"><![CDATA[用作变量名_有时会被用作变量名，表示是一个临时变量，后面不会被用到。 12for _ in range(5): print(&apos;hahaha&apos;) 放在变量名前_var or_func在变量名前加一个_表示这个变量名或者方法是私有的，不对外开放。 __var or __func在变量名前加__双下划线，表示该变量或者方法不可被覆盖. 实际上python内部通过在该变量名或者方法名前添加_classname__methodName的方式来防止覆盖。 123456789101112131415161718class A(object): def __init__(self): pass def __method_show(self): print(&quot;A&quot;)class B(A): def __init__(self): pass def __method_show(self): print(&quot;B&quot;)if __name__ == &apos;__main__&apos;: a = A() print(dir(A)) print(dir(B))[&apos;_A__method_show&apos;, &apos;__class__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__getattribute__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__module__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;, &apos;__weakref__&apos;][&apos;_A__method_show&apos;, &apos;_B__method_show&apos;, &apos;__class__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__getattribute__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__module__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;, &apos;__weakref__&apos;] __var__被用作python中的特殊方法名，保证不会和用户自定义的方法名冲突，如__name__, __init__等。 Reference reference refercnce]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中*的用法]]></title>
    <url>%2F2018%2F05%2F28%2Fpython-star%2F</url>
    <content type="text"><![CDATA[*args 与 **kargs*args 常作为变量用在func中，表示一组(list or tuple)变量 1234567def add(*args): sum = 0 for num in args: sum += num return sumif __name__ == &apos;__main__&apos;: print(add(1,2,3,4,5)) 123456def test(**kargs): for key, value in kargs.items(): print(key,value)if __name__ == &apos;__main__&apos;: test(a=1, b=2) 在list或tuple赋值中使用*123iterData = list(range(100))begin, *middle, end = iterDataprint(begin, middle, end) 在zip()中使用的*123456def test_zip(): a = [1,2,3,4,5] b = [6,7,8,9,10] c = list(zip(a,b)) # 解压 print(c) print(list(zip(*c))) # 压缩 Reference python cookbook problems solving using algorithms and data structures]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Cookbook Notes Data Structure]]></title>
    <url>%2F2018%2F05%2F27%2Fpython-cookbook-data-structure%2F</url>
    <content type="text"><![CDATA[解压可迭代对象赋予多个值12a = [1,2,3,4,5,6]x,*y,z = a You will get x=1, y=[2,3,4,5], z=6. 保留最后n个元素可以使用collections.deque双向队列来实现, deque(maxlen=N) 可以定义一个长度为N的队列。 queue = deque(5), queue.append() 从队尾append queue.pop() 从队尾pop queue.appendleft() 从队首插入 queue.popleft() 从队首pop 查找最大或者最小的N个元素可以使用python中的堆, import heapq, heapq 中提供了nlarest 和nsmallest 方法. 堆是一种特殊的数据结构，是一个完全二叉树。根据parent节点值不大于(小于)其左右子节点值，堆又可以分为最小堆和最大堆。python 中的heapq 提供了堆的数据结构实现，以及相关的堆算法。 12345heapq.nlargest(n, heap, key=None), key 为类似sorted中的keyheapq.nsmallest(n, heap, key=None)heapq.heapify(list), to construct a heap given a listheapq.heappush(heap, item)heap.heappop(heap, item) 时间复杂度 堆的插入和删除复杂度 O(logn), 查询O(n). 对长度为N的list，选出n个最小的元素，复杂度为O(Nlogn), 对N个元素进行遍历，维护一个大小为n的最小堆，每次插入复杂度为O(logn). 实现一个PriorityQueue实现一个PriorityQueue， 并且在pop的时候，优先级最高的元素先出。可以考虑用heap，python中的heapq是一最小堆， 因此需要将priority取负数，同时添加index，使得当priority相同的时候可以通过index来进行比较。 1234567891011121314151617import heapqclass PriorityQueue: def __init__(self): self._queue = [] self._index = 0 def push(self, item, priority): heapq.heappush(self._queue, (-priority, self._index, item)) self._index += 1 def pop(self): return heapq.heappop(self._queue)[-1] class Item: def __init__(self, name): self.name = name 这里需要提到的是，如果直接比较Item(&#39;a&#39;) &lt; Item(&#39;b&#39;), 是不支持的(需要override __gt__等方法)， 但是(1, Item(&#39;a&#39;)) &lt; (2, Item(&#39;b&#39;) 元组之间是可以进行比较的。 DefaultDict 和 OrderedDict defaultdict 可以为每一个key的值进行初始化，常用在一个key有多个值的情况，即该key对应了list()或者tuple. OrderedDict 在构建dict的时候，可以保存将pair put进dict中的顺序，类似于java中的LinkedHashMap. Python 中的OrderedDict维护了一个根据键值插入顺序的双向链表， 即每次该键值插入时，会在链表尾部添加该键值, 重复的键值不会影响链表机构。因此， OrderedDict 的内存开销是正常dict开销的两倍，在内存消耗较大的场景需要谨慎考虑是否使用OrderedDict. 123456789101112from collections import OrderedDictfrom collections import defaultdictd = defaultdict(list)d[&apos;a&apos;].append(1)d[&apos;a&apos;].append(2)print(d[&apos;a&apos;])orderedDict = OrderedDict()orderedDict[&apos;a&apos;] = &apos;a&apos;orderedDict[&apos;b&apos;] = &apos;b&apos;print(orderedDict) 词典的运算 在需要对词典的值进行排序，取最大最小值的同时，返回该值的键值，可以用下面的方法快速实现： 12345678data = dict()data[&apos;a&apos;] = 1data[&apos;b&apos;] = 2data[&apos;c&apos;] = 10print(data)print(min(zip(data.values(), data.keys()))) # zip()为只可迭代一次的迭代器print(max(zip(data.values(), data.keys())))print(sorted(zip(data.values(), data.keys()))) 在需要查找两个词典的相同处和不同处的时候，可以使用： 123456a = &#123;&apos;a&apos;:1, &apos;b&apos;:2, &apos;c&apos;:3&#125;b = &#123;&apos;a&apos;:1, &apos;d&apos;:5, &apos;z&apos;:6&#125;print(a.keys() &amp; b.keys())print(a.keys() - b.keys())print(a.items() &amp; b.items())print(a.items() - b.items()) dict的items()和keys() 返回一个集合，因此可以使用集合的操作来实现。但是dict的values()不能使用这个功能，主要是values()的值不能保证完全unique，可以先将values()转换成set，然后在操作. Counter123456789from collections import Countera = [1,2,3,4,5,1,2,4,5,6,7]b = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]counter = Counter(a)print(counter.most_common(3)) # get top 3 print(counter[1]) # 内部本质就是dictprint(counter[2])a + b # Counter支持 集合操作a - b itemgetter() &amp;&amp; attrgetter()在python中，sorted(iterable, cmp=None, key=None, reverse=False)、min()等函数常有key可以自定义一些行为。当然这里我们可以传入一个function对象，或者用一个lambda表达式来解决。但是其实我们可以使用operator中的itemgetter()和attrgetter()来提高效率。 123456789101112131415rows = [ &#123;&apos;fname&apos;: &apos;Brian&apos;, &apos;lname&apos;: &apos;Jones&apos;, &apos;uid&apos;: 1003&#125;, &#123;&apos;fname&apos;: &apos;David&apos;, &apos;lname&apos;: &apos;Beazley&apos;, &apos;uid&apos;: 1002&#125;, &#123;&apos;fname&apos;: &apos;John&apos;, &apos;lname&apos;: &apos;Cleese&apos;, &apos;uid&apos;: 1001&#125;, &#123;&apos;fname&apos;: &apos;Big&apos;, &apos;lname&apos;: &apos;Jones&apos;, &apos;uid&apos;: 1004&#125;]from operator import itemgettera = sorted(rows, key=itemgetter(&apos;uid&apos;), reverse=True) # itemgetter() 常用在支持原生比较的对象a1 = sorted(rows, key=lambda r: r[&apos;uid&apos;])b = sorted(rows, key=itemgetter(&apos;fname&apos;))b1 = sorted(rows, key=lambda r: r[&apos;fname&apos;])print(a)print(a1)print(b)print(b1) 1234567891011121314from operator import attrgetterclass User: def __init__(self, user_id): self.user_id = user_id def __repr__(self): return &quot;User(&#123;&#125;)&quot;.format(self.user_id)users = [User(1), User(5), User(3)] a = sorted(users, key=lambda u: u.user_id, reverse=True)b = sorted(users, key=attrgetter(&apos;user_id&apos;)) ## attrgetter() 常用在不支持原生比较的对象print(a)print(b) itertools.groupby() 通过某个字段进行分组1234567891011121314151617181920rows = [ &#123;&apos;address&apos;: &apos;5412 N CLARK&apos;, &apos;date&apos;: &apos;07/01/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;5148 N CLARK&apos;, &apos;date&apos;: &apos;07/04/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;5800 E 58TH&apos;, &apos;date&apos;: &apos;07/02/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;2122 N CLARK&apos;, &apos;date&apos;: &apos;07/03/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;5645 N RAVENSWOOD&apos;, &apos;date&apos;: &apos;07/02/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;1060 W ADDISON&apos;, &apos;date&apos;: &apos;07/02/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;4801 N BROADWAY&apos;, &apos;date&apos;: &apos;07/01/2012&apos;&#125;, &#123;&apos;address&apos;: &apos;1039 W GRANVILLE&apos;, &apos;date&apos;: &apos;07/04/2012&apos;&#125;,]from itertools import groupbyfrom operator import itemgettersorted_rows = sorted(rows, key=itemgetter(&apos;date&apos;)) ## groupby() 只查找连续相同值，因此需要先根据该字段进行排序for date, items in groupby(sorted_rows, key=itemgetter(&apos;date&apos;)): ## groupby 返回group的字段值，并且在该字段值下的一个迭代器对象 print(date) for i in items: print(&apos;&apos;, i) filter 过滤序列中的元素在python中我们像过滤一个序列中的元素，常用到推到式，例如: 1234nums = [n for n in range(10) if n &gt; 5]print(nums)nums = [n if n &gt; 5 else 0 for n in range(10) ]print(nums) 但是在输入非常大的时候，由于推到式会将全部结果load进内存，导致内存消耗过大，这个时候我们可以使用生成器表达式来解决： 123456789def print_nums(nums): for n in nums: print(n) nums = (n for n in range(100) if n &gt; 3)print_nums(nums)nums = (n if n &gt; 3 else 0 for n in range(100))print_nums(nums) 有时会出现过滤条件比较复杂的情况，不能在推到式或者生成器表达式中简单的表达出来，这个时候可以使用python built-in function filter. 1234567891011values = [&apos;1&apos;, &apos;2&apos;, &apos;-3&apos;, &apos;-&apos;, &apos;4&apos;, &apos;N/A&apos;, &apos;5&apos;]def is_int(val): try: a = int(val) return True except: return False filtered = list(filter(is_int, values)) ## filter 返回一个迭代器print(filtered) 从字典中提取子集从字典中提取子集有以下若干种方式，经试验，字典推倒式更清晰，并且性能最好 1234567891011121314151617prices = &#123; &apos;ACME&apos;: 45.23, &apos;AAPL&apos;: 612.78, &apos;IBM&apos;: 205.55, &apos;HPQ&apos;: 37.20, &apos;FB&apos;: 10.75&#125;tech_names = &#123;&apos;AAPL&apos;, &apos;IBM&apos;, &apos;HPQ&apos;, &apos;MSFT&apos;&#125;p1 = &#123;key:value for key, value in prices.items() if key in tech_names&#125; ## 字典推倒式，更清晰，性能更好print(p1)p2 = dict((key,value) for key,value in prices.items() if key in tech_names)print(p2)p3 = &#123;key:prices[key] for key in prices.keys() if key in tech_names&#125;print(p3) namedtuple1234567891011121314151617from collections import namedtupleStock = namedtuple(&apos;Stock&apos;, [&apos;name&apos;, &apos;shares&apos;, &apos;price&apos;]) ## namedtuple 是标准元组(tuple)子类的一个工厂方法s = Stock(&apos;alibaba&apos;, 8080, 25)name, shares, price = sprint(name)print(shares)print(price)def compute_cost(records): total = 0.0 for rec in records: total += rec.shares * rec.price return totalrecords = [Stock(&apos;alibaba&apos;, 8080, 25), Stock(&apos;tencent&apos;, 8888, 20)]print(compute_cost(records)) 使用生成器表达式–转换并同时计算数据在很多时候，我们会用any, sum等函数，但是如果我们先计算得到一个临时list， 再通过any等函数计算，会多一个步骤。更优雅的方式是使用生成器表达式来转换并同时计算数据。 123nums = [1, 2, 3, 4, 5]sum_value = sum(num*num for num in nums)print(sum_value) ChainMap现在假设你必须在两个字典中执行查找操作（比如先从 a 中找，如果找不到再在 b 中找）。 一个非常简单的解决方案就是使用 collections 模块中的 ChainMap 类。 一个 ChainMap 接受多个字典并将它们在逻辑上变为一个字典。 然后，这些字典并不是真的合并在一起了， ChainMap 类只是在内部创建了一个容纳这些字典的列表 并重新定义了一些常见的字典操作来遍历这个列表。 123456789from collections import ChainMapa = &#123;&apos;x&apos;: 1, &apos;z&apos;: 3 &#125;b = &#123;&apos;y&apos;: 2, &apos;z&apos;: 4 &#125;chain_map = ChainMap(a, b)print(chain_map[&apos;x&apos;])print(chain_map[&apos;y&apos;])print(chain_map[&apos;z&apos;]) # 都有的话使用第一个dict中的元素，同理删除和更新也是更新第一个字典中的该字段的值 Reference Python Cookbook reference for itemgetter() reference for attrgetter()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>python</tag>
        <tag>coding</tag>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Conda Summary]]></title>
    <url>%2F2018%2F05%2F21%2Fconda-notes%2F</url>
    <content type="text"><![CDATA[Conda Environment list all conda envs: conda env list create conda env: conda create --name test python=3.4, if not specify python version, conda will ues the same python version as the python version in conda. conda activate env: source activate env_name conda deactivate env: source deactivate env_name create conda from file: conda env create -f environment.yml conda export environment config: connda env export &gt; environment.yml conda remove an environment: conda remove --name env_name --all Conda Package conda search package: conda search tensorflow conda install package in a specific env: conda install --name env_name tensorflow conda install package in the current env: conda install tensorflow=1.4.0, if not given package version, the latest version will be uesd. conda list all packages in the current env: conda list conda update pacakge: conda update tensorflow conda remove package: conda remove -n env_name tensorflow if cannot find package by conda, you can use pip install package_name. Reference Conda Documentation]]></content>
      <tags>
        <tag>python</tag>
        <tag>conda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jupyter Notebook Summary]]></title>
    <url>%2F2018%2F05%2F21%2Fjupyter-notes%2F</url>
    <content type="text"><![CDATA[Jupyter Install use conda install jupyter use pip install jupyter Use Jupyter On Gpu Server First, start jupyter-notebook on GPU Then, use ssh myserver -L 8888:localhost:8888 to link local port 8888 to gpu server port 8888 Use Conda Virtual Environment On Jupyter install plugins on conda conda install nb_conda Every time you switch to a new environment, you need to run conda install nb_conda to enable the environment choice in jupyter notebook. Jupyter Shortcut Keys:Command Mode press esc to enter command mode x cut cell c copy cell v copy cell to the downside Shift + v copy cell to the upside a create cell to the downside b create cell to the upside dd delete cell ctrl + s save jupyter file shift + m merge cell m change cell to markdown y change cell to code Edit Mode press enter to enter edit mode tab auto-completition shift + tab show instructions ctrl + enter run current cell shift + enter run current cell and go to next cell alt + enter run current cell and insert a new cell below Use Jupyter Extensions, e.g., vim First install IPython-notebook-extensions by 12$ pip install https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tarball/master$ jupyter contrib nbextension install --user Install Vim Extensions: 12345# 在 ~/.local/share/jupyter/ 建立nbextensions資料夾$ mkdir -p $(jupyter --data-dir)/nbextensions# Clone the repo$ cd $(jupyter --data-dir)/nbextensions$ git clone https://github.com/lambdalisue/jupyter-vim-binding Reference reference link Vim Extensions Shortcut Reference]]></content>
      <categories>
        <category>python</category>
        <category>tools</category>
        <category>conda</category>
        <category>jupyter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>conda</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Learning To Rank]]></title>
    <url>%2F2018%2F03%2F08%2Flearning-to-rank%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>summary</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven Summary]]></title>
    <url>%2F2018%2F03%2F05%2Fmaven-notes%2F</url>
    <content type="text"><![CDATA[Show Super Pom mvn help:effective-pom Show all dependencies mvn dependency:tree RM dependnecy in pom123456&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.group&lt;/groupId&gt; &lt;artifactId&gt;name&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt; Reference http://wiki.jikexueyuan.com/project/maven/pom.html]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>package management</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ali Xiaomi Transfer Learning]]></title>
    <url>%2F2018%2F03%2F04%2Ftransfer-learning-alimi%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[DrQA]]></title>
    <url>%2F2018%2F03%2F04%2Fdrqa%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Design Pattern]]></title>
    <url>%2F2018%2F02%2F27%2Fdesign-pattern%2F</url>
    <content type="text"><![CDATA[Singleton Instance123456789101112131415161718public class Test &#123; private static final class SingletonHolder &#123; private static final Test INSTANCE = new Test(); &#125; private Test() &#123; &#125; public static Test getInstance() &#123; return SingletonHolder.INSTSNCE; &#125; public static void main(String[] args) &#123; Test test = Test.getInstance(); &#125;&#125;]]></content>
      <categories>
        <category>Design Pattern</category>
      </categories>
      <tags>
        <tag>engineering</tag>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的String, StringBuilder和 StringBuffer]]></title>
    <url>%2F2018%2F02%2F26%2Fjava-notes%2F</url>
    <content type="text"><![CDATA[StringBuilder 与 StringBuffer StringBuilder 执行速度比StringBuffer要快，但是StringBuilder不是线程安全的 StringBuffer 是线程安全的，执行速度比StringBuilder要慢 String在java中，String字符串常量是不可改变的对象，每当在String上进行操作时，实际上都是在创建一个新的String对象。以下代码： 121. String s = &quot;abx&quot;;2. String s = s + &quot;ds&quot;; 其中，第二行中的s会被重新创建，原来的对象会被GC掉。而StringBuilder和StringBuffer是可变对象，在同一个对象上进行操作。 值得注意的一点是： 1String s = &quot;this &quot; + &quot;is &quot; + &quot;my &quot; + &quot;home&quot; 等同于String s = &quot;This is my home&quot;, 在这种情况下String操作要比StringBuilder和StringBuffer要快，是JVM的一个把戏。但是当字符串拼接中有其他的String变量时，JVM就会按照原来的方式来做。 Reference http://www.cnblogs.com/A_ming/archive/2010/04/13/1711395.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>engineering</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Coding Style]]></title>
    <url>%2F2018%2F02%2F11%2Fpython-coding-style%2F</url>
    <content type="text"><![CDATA[Name Convention module_name, package_name, ClassName, method_name, ExceptionName, function_name, GLOBAL_CONSTANT_NAME, global_var_name, instance_var_name, function_parameter_name, local_var_name CLASS_CONSTANT_NAME Reference Goole Python Coding Style]]></content>
      <categories>
        <category>coding style</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>summary</tag>
        <tag>python</tag>
        <tag>coding style</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cuda Notes]]></title>
    <url>%2F2018%2F02%2F08%2Fcuda-notes%2F</url>
    <content type="text"><![CDATA[Nvidia CUDA 9.1 Install download runfile from here install according to the instructions add the path, i.e. PATH and LD_LIBRARY_PATH, to your ~/.bashrc like this: 12export PATH=$PATH:/usr/local/cuda-9.1/bin/export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.1/lib64 NVCC Usage show version: nvcc --version show help: nvcc --help 查看nvidia gpu 使用情况 nvidia-smi]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>ubuntu</tag>
        <tag>cuda</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac Cassandra Notes]]></title>
    <url>%2F2018%2F01%2F04%2Fcassandra-note%2F</url>
    <content type="text"><![CDATA[Mac cassandra installInstall Instructions Mac Cassandra start and stop start: brew services start cassandra stop: brew services stop cassandra]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>cassandra</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL Summary]]></title>
    <url>%2F2017%2F12%2F18%2FNoSQL%2F</url>
    <content type="text"><![CDATA[NoSQL SummaryNoSQL指 not only SQL, 主要包括： Key-value: Redis, 分布式：Codis以键值对的方式进行存储，其内部通常用哈希表的结构来对数据进行存储。在使用时，用户只需要根据key来访问即可。优点：对单条数据的增删改查非常迅速；缺点：数据库不知道对于数据本身的任何信息，往往需要对数据库中的数据进行遍历，不支持索引。Key-value型数据库通常在服务中作为缓存端使用，例如可作为MYSQL的缓存端使用，可使得服务性能提高10+倍。 Document-based: mongoDB与Key-value数据库不同，Document-based 数据库中存储的不再是字符串，而是像JSON, XML等具有特定格式的文档。这些文档可以记录键值对，数组，或者是内嵌的文档。Document-based数据库常常支持索引，因此Document-based数据库既保留了key-value型数据库的便利，又在查询上借助索引可以达到不错的性能。 Column-based: cassandra, Hbase按照列来在数据文件中记录数据，以便获得更好的遍历和请求效率，但并不是所有的数据都用列来存储，一般只有需要请求的数据会用列来存储。 Graph-based: neo4j, janus graph, dgraph图数据库存储的时候是以图的形式保存的，对应底层数据结构是邻接表。 图数据库查关系的时候速度很快；传统关系型数据库在查关系的时候需要join很多张表，速度比较慢。 传统关系型数据库存储的数据是结构化的，表的字段是固定的，数据规整，省空间，但是需要提前设计好表的结构，改动表结构代价比较大。图数据库的字段是不固定的，不用提前设计表的结构，改schema的代价很小。 Reference https://www.cnblogs.com/loveis715/p/5299495.html https://www.cnblogs.com/aspwebchh/p/6652855.html]]></content>
      <tags>
        <tag>notes</tag>
        <tag>summary</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vimium Notes]]></title>
    <url>%2F2017%2F12%2F04%2Fvimium-notes%2F</url>
    <content type="text"><![CDATA[Vimium IntroductionVimium 是chrome浏览器中的一款非常好用的插件，通过vimium，你将告别鼠标和触摸板，开始各种神操作。 Vimium Summary Picture Vimium Summary同vim使用比较相似，常用的vimium操作有 j 向下翻， d向下翻页 k 向上翻， u向上翻页 h 向左翻， l 向右翻 x 关闭当前页面， X回复关闭页面 t 新建网页标签 yy 粘贴当前网页链接 gg 到网页顶端，G到网页底端 T 查看当前浏览器所有网页 o 打开浏览历史、标签；O 在新的标签页中打开 r 重新加载标签页 f 打开当前网页中的链接 / 进入搜索模式， n 向下搜， N往回搜]]></content>
      <categories>
        <category>vimium</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>tools</tag>
        <tag>vim</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TF Symposium 1.4.0 Summary]]></title>
    <url>%2F2017%2F10%2F25%2Ftf_symposium%2F</url>
    <content type="text"><![CDATA[TF Symposium SummaryL2L with 进化算法 by YiFei Feng 循环网络： 控制器； evolution algo： 淘汰 -&gt; 变异 用简单的模型初始化 重复进化步骤 TF 与 生物学 生物大数据 机器学习问题： regression，classification Deep Variant: inception-v3,将在第四季或明年开源 TF 性能 by Frank Chen 出现性能问题： 了解问题， 用分析器： Timeline TF自带分析器, 用chrome打开profile文件， 查看瓶颈 复制内存：复制越多， tf运算图越慢 如何改进： 1. 优化输入管道， 使用流水线； 2. 优化模型计算， 使用fuzed batch-norm, 使得在GPU上更快；3. 数据格式， CPU，GPU数据格式； 4. 运算图， matcol； 5. 单GPU变量：变量放到一个GPU即可； 单机多GPU， 可以尝试使用GPU来作为变量ser ver；变量过大或者过多， 多GPU共享变量； 多机多GPU， 通过网络赋值内存，比单机慢；可以使用local CPU做cache； 高级分布式培训模式：在每一个GPU集群内部，使用一个GPU作为parameter server，在外部用cpu做cache。 TF 机器人应用 by Pi-Chuan Chang Challenges: safety, control, transfer Minitaur: -&gt; robot platform openAI Gym environemt interface -&gt; environment agnet: 树莓派； 微控制器计算能力不足 ARChirecture: signal generator (sin() function -&gt; 周期性) + balanbce controller(Fully connected layers) -&gt; actions transfer to real robot: system identification, env randomization TF 高层API by Yifei Feng Keras： 高层神经网络API， 默认使用tf作为后端 tf.keras: 自定义的tf后端，change: from keras -&gt; from tensorflow.keras tf.layers and tf.keras.layers, 共享实现方式，基本上相同 Estimators: canned estimators, 实现好的模型 keras 模型 -&gt; model_to_estimator -&gt; estimator model Distributed TF tf的一个很大优势， dev summit 2017 estimators 可进行分布式执行 1.4 版本中找到 Advice 使用可以使用的最高层的API 用tf.layers and tf.keras 编写自定义模型 分布式训练 Estimators， 大部分情况下最好的选择 TF Serving github.com/tensorflow/serving c++ libraries ： tf模型保存/输出格式； 通用核心模式 tf serving binariesL开箱急用的最佳实践， Docker容器， K8s教程 get it pip apt-get 安装 www.tf.org/serving TF Lite（On Smart Devices） offline running on small devices low-bandwidth, latency, power Chanllenges: bandwith memory computation cpus Tf works well on large services, tf-lite works on small devices small binary size, low-overhead, optimized set of kernels four parts: intepreter (optimized for all devices: few dependencies, small library less than 300k, fast load time, static memory plan, but no control flow), OPs/ kernels (NEON on ARM, Float &amp; quantized, many kernels for mobile apps), model file format (flatbuffers) mmap, more efficient than protocol buffer ; Hardware Acceleration (e.g., Android: Neural Network API; IOS: Core ML); Neural Network API: Part of Android Framework, tries to use as much hardware as possible. Release Developer preview: C++ and JAVA API TOCO Converter A set of builtin ops Demo applications Example models MobileNet(Float) Teaching Machines to Draw sketch-RNN: K encoder -&gt; Z (Latent Space Vectors)-&gt; Decoder]]></content>
      <categories>
        <category>tensorflow</category>
        <category>notes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>summary</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dive Into Python3 Notes Native Datatypes]]></title>
    <url>%2F2017%2F10%2F19%2FDive%20Into%20Python3%20Notes%20-%20Native%20Datatypes%2F</url>
    <content type="text"><![CDATA[Dive Into Python3 Notes - Native Datatypes在python中，任何value都有type，但是你不需要显式地声明value的类型。Python根据该变量第一次被赋值的不同来对该变量的类型做出推断。 Python中主要的数据类型有： Boolean： True or False Numbers： they can be integers，floats，fractions(1/3) and even complex numbers Strings: an sequence of Unicode characters Bytes and byte arrays: e.g., an jpeg image List: ordered sequence of values Set: unordered sequence of values Tuple: ordered and immutable sequence of values Dict: unordered key-value pairs Number use type() and isinstance() to get the datatype and judge use int(2.0) and float(1), int(-2.5) = -2 来做type转换 float numbers 小数点后最多只能有15位 与python2既有int又有long不同， python3中只有int， 并且int可以取得像python2中long的最大值 Number Operations / 除法， 返回float类型 // 整数除法： 11 // 2 = 5, -11 // 2 = -6 ** 幂操作 % 取余数 分数 Fractions 使用 import fractions, print(fractions.Fraction(1, 3)) 其他数字 PI : import math, print(math.pi) 需要注意的是python中没有infinite的精度， 因此像sin(\pi)的结果不是0， 而是一个很小的数 数字用在 bolean context 如果数字的value为0， 则为False； 否则为True ListPython中list大小可以动态改变，并且list中可以add各种不同类型的value。 Define a listDefine a list a = [] or a = [1, &#39;hello&#39;, 1.0, [1,2,3]] Get the values from the listGet the values from the list: a[0], a[1], a[2], a[3] or a[-1], a[-2], a[-3], a[-4] Slicing the listSlicing the list: a[1:3] can get the sublist of a[0] and a[1], 即不包括最后的一位；如果前后有省略，则默认为从该list的第一位开始(包含)，或者到最后一位(包含)；如果前后都没有，则结果为整个list 12a[:2] -&gt; [1, &apos;hello&apos;]a[2:] -&gt; [1.0, [1,2,3]] Adding items to list:Four ways to add items to a list: Operation + : a = [1, 2], b = [2], a = a + b -&gt; [1,2,2], 这里需要注意的是， +操作会new 一个新的list a.append()函数, append()函数会把append的内容(无论什么类型)加到list中, 例如： a.append([4,5,6]) -&gt; a = [1,2,2,[4,5,6]] a.extend([4,5,6])函数会把extend的内容一个一个的加到list中， 得到a = [1,2,2,4,5,6] a.insert(0, &#39;4&#39;), 会把value插入到指定的index处 Searching in a list a_list.count(&#39;a&#39;): return the number of specific values in a list &#39;a&#39; in a_list, return a boolean value to show if the value is in the list a_list.index(&#39;a&#39;) to return the index of the given value Removing items in a list del a_list[1] to delete the value in the index of 1 a_list.remove(&#39;a&#39;) to remove the first occurance of the value in a list a_list.pop() removes the last value in a list a_list.pop(0) removes the value in the given index List in a boolean context empty list will be False in a boolean context and list which is not empty will be True. TuplesA tuple is an immutable list. A tuple cannot be changed once it is created. Tuple和List比较像， tuple可以看做是一个不可变的list。Tuple比list更快，如果这个set是不会被更改的，则使用Tuple，同时它也会使你的code更加安全。 在Python中，只有immutable的才可以作为Dict 的key，如果tuple中的变量都是immutable的，那么 Tuple的创建和获取元素 a_tuple = (1,2,3,Ture), Tuple用圆括号来创建，元素获取的方式同list Tuple的slice方式a_list[1:3]同list，不同之处在于，tuple的slice返回的仍是tuple Tuple中元素的操作 Tuple元素的操作不包括：如 pop(), append()等添加或者删除元素的函数 Tuple中可以使用count()和index(), &#39;a&#39; in a_tuple等操作 Tuple 和 List的转换 tuple() functuon can convert list into tuples and list() function can convert tuples into list. Tuples in boolean context 同list一样， 在boolean context中，如果tuple为空，则返回False； 否则返回True 值得注意的是，在创建只有一个值的tuple时，应为(False,)；即需要加一个逗号”，“， 否则python无法识别出是带有一个值的tuple。 将tuple用来同时给多个变量赋值 (x, y, z) = (1,2,3) Set在python中， set是无序的，并且没有冗余元素的数据结构。A single set can contain values of any immutable datatype, 因此像list不能是set中的元素，因为list不是immutable的，但是tuple可以。 Set的创建 a_set = {1,2,3} 可以用来创建一个set， 但是{}为一个空的dict； set()才是创建一个空set的方式。 同时也可以使用set([1,2,3])函数来将一个list转换为一个set，此操作不会对list做改变。 增加和删除set中的元素增加set中的元素： a_set.add({1,2,3}), 同list中的append()一样， 会将传进去的datatype加到一个变量中去 a_set.update({1,2,3}，{1，2，3}), 同list中的extend()一样， 会将set或者list中的每一个元素加到set中，并且会去除重复元素，保证unique。 删除set中的元素： a_set.discard(1) 将会删除set中的变量1，如果变量1不存在，没有任何影响； a_set.remove(1)将会删除set中的变量1，如果变量1不存在，则会raise Exception KeyError。 a_set.pop() 将会随机删除set中的一个元素，因为set是无序的，因此不能像list一样pop掉最后的元素。 a_set.clear() 将会clear掉set的全部元素，返回一个空的set Set的操作 1 in a_set will return True if a_set contains 1, otherwise return False a_set.union(b_set) 将会把 a_set和b_set取并集 a_set.intersection(b_set) 将会取a_set 和 b_set 的交集 a_set.difference(b_set) 将会取在a_set 但是不在b_set中的元素 a_set.symmetric_difference(b_set) 将会取只出现在a_set 和 只出现在b_set的并集 Set in a boolean context 同list 和tuple 一样，空的set在boolean context中为False，否则为True Dictionary在python中，Dictionary为无序的key-value pair的set。当向dict中添加一个key的时候，你也必须添加一个相应的值。 Dict的创建和元素获取 {} 为空的dict， a_dict = {&#39;1&#39;: &#39;h&#39;, &#39;2&#39;: &#39;w&#39;} 创建一个dict a_dict[&#39;1&#39;] 根据相应的key，来获取对应的value； 当a_dict[&#39;3&#39;] 获取一个未包含的key的时候，会raise KeyError Exception Dict的更改 a_dict[&#39;3&#39;] = &#39;hhh&#39;来增加新的key-value pair a_dict[&#39;1&#39;] = &#39;hh&#39; 来对已经存在的key-value pair进行更改 Mixed Value DictDict 的value可以是任何类型， 但是dict的key 需要时immutable的， 例如： integer， string， tuple等。 和list、set、tuple等一样, dict可以用len()来返回key-value pair的个数 和list、set、tuple等一样， 可以使用in 来判断一个变量是不是dict中的一个key Dict in a boolean context An empty dict is False Otherwise, it’s True None None 是Python中一个比较特殊的constants，它是一个null值。 None有他自己特殊的type，为NoneType 将None同其他不是None的值进行比较，都将返回False。 所有的None值 (值为None的变量) 都相等。 Reference [Dive into Python 3] (http://www.diveintopython3.net/)]]></content>
      <categories>
        <category>python</category>
        <category>notes</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>notes</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dive Into Python3 Notes Your First Program]]></title>
    <url>%2F2017%2F10%2F15%2FDive%20Into%20Python%20Notes%2F</url>
    <content type="text"><![CDATA[Dive Into Python3 Notes - Your First ProgramDefine Functions python function中没有定义返回类型。 每一个python functiuon都会有一个返回值，如果function中含有return value， 则返回相应的值；否则返回None(Python中的null) 在python中， 变量(anything)从不显示声明类型，python 内部会自动track相应的类型，内部根据该变量第一次被赋予的类型来决定该变量的类型。 python function允许参数有默认值，如果该参数没有被输入，则使用该参数的默认值；另外，function参数的指定，可以不按照在function中定义的顺序，只要提供该function中的变量名字即可。 Writing Readable CodeDocumentation Strings (doc-string for short) “”” “”” triple quotes signify a multi-line doc-string. Doc-string 必须在相应函数(类)中最前的地方被定义，在Python中， everything is object， doc-string 可以通过该object的.__doc_string得到。 Python Import Path 在Python中，当你想import其他python module的时候，python会首先去几个地方进行查找。 Specifically, python会在sys.path中的所有目录下进行查找。 sys.path 是一个list， 你可以像操作正常的list一样将你的python module加入到sys.path中，例如： 12import syssys.path.insert(0, &quot;./tmp/hello_world.py&quot;) Everything Is Object In Python Python module is a object, so when you want to use the public functions, classes or attributes in the module, you need to add the module name before that, e.g., FirstProgram.HelloWorld() Python function is also a object, so you can use FunctionName.__doc__ to get its doc-string. In python, classes, functions, modules are first-class objects, which means you can pass them as a parameter in a function. Python Indenting Code 在python中，函数没有显式的begin、end标志，也没有像java等语言用{}来标记函数的start和end。Python中用冒号:和缩进。 可以这样简单的理解，像在java中，涉及到code block的地方，需要有{}来标记，例如if， for， while， function等；在python中对于这些部分需要有:和缩进 Exceptions In Python If you’re opening a file, it might not exist. If you’re importing a module, it might not be installed. If you’re connecting to a database, it might be unavailable, or you might not have the correct security credentials to access it. If you know a line of code may raise an exception, you should handle the exception using a try...except block, and raise to generate exceptions. 例如： 1234try: import chardetexcept ImportError: chardet = None In Python, everything is case-sensitiveRunning ScriptsPython modules are objects and you can use some attributes of them: all modules have an attribute: __name__. 如果你是import a module， __name__即为该module的filename (不带路径名)；但如果你将该module单独的去run，此时__name__的值为它的default值：__main__ Reference [Dive into Python 3] (http://www.diveintopython3.net/)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>notes</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Summary]]></title>
    <url>%2F2017%2F10%2F03%2FMySQLNotes%2F</url>
    <content type="text"><![CDATA[MySQLMysql 是最流行的关系型数据库管理系统，由瑞典MySQL公司开发，目前属于Oracle。MySQL使用标准的SQL数据语言形式。 Concept In MySQL 主键： 主键是唯一的，一个数据表只能有一个主键， 可以用主键来查询数据。 外键：用于关联两个数据表。 复合键(组合键)：将多个列作为一个索引键，一般用于复合索引。 MySQL Install and Setup service mysqld start 启动mysql mysql -h localhost -u root -p 进入mysql client端进行执行简单的SQL命令 quit OR Ctrl + D 退出mysql。 mysqladmin -u root password &quot;new_password&quot;; to set new password. SHOW DATABASES; to list all databases MySQL 数据类型MySQL中主要有三种数据类型：熟悉、日期|时间、字符串，MySQL支持所有标准SQL数值数据类型 See more info.。 MySQL 数据库操作命令 SHOW DATABASES; To list all databases use XXX; To choose the XXX database SHOW TABLES; 列出该数据库中所有表 SHOW COLUMNS FROM XX OR DESCRIBE XX; 显示数据表的属性信息 SHOW INDEX FROM XX 显示数据表的详细索引信息 SHOW TABLE STATUS FROM XXX 显示数据库管理系统的性能及统计信息 SHOW TABLE STATUS FROM XXX LIKE &#39;runoob%&#39; 显示以runoob开头的表的信息 SHOW TABLE STATUS FROM XXX LIKE &#39;runoob%&#39;\G 显示以runoob开头的表的信息, 结果按照列打印 select version(),current_date(); 显示版本和日期， 可见mysql对大小写结果一致。也可多行语句， 直到见到”;”为止。 MySQL 常用操作命令 create database XXX; 创建数据库XXX deop database XXX; 删除数据库XXX use XXX; 选择数据库XXX CREATE TABLE table_name(column_name column_type); 创建数据表 例如：1mysql&gt; create table test_table( id INT NOT NULL AUTO_INCREMENT, name VARCHAR(20) NOT NULL, sex CHAR(1) NOT NULL, birth DATE, birth_addr VARCHAR(20), PRIMARY KEY (id)); drop table XXX; 删除数据表； insert into table_name (filed1, ...fieldn 可省略) values (value1, value2, ...valuen) 插入数据； 例如： 1insert into test_table values (1, &apos;john&apos;, &apos;m&apos;, &apos;1992-01-29&apos;, &apos;shanghai&apos;); select * from table_name;显示该表下的全部数据； MySQL 查询数据语句： 1234SELECT column_name,column_nameFROM table_name1, table_name2[WHERE Clause][OFFSET M ][LIMIT N] 例如： 1select name,sex from test_table where id &gt; 1 limit 1; update table_name set field1=new-value1, field2=new-value2 更新数据 例如： 1update test_table set name=&apos;mike&apos; where id=1; delete from table_name [where clause]; 删除表中数据，若没有指定条件，则删除整个表。 WHERE FIELD LIKE &#39;%XXX&#39;; Like子句 + %，起到查询包含XXX的数据的左右， 例如： select name from test_table where birth like &#39;1992%&#39;; WHERE NAME REGEXP &#39;regex expression&#39;, 例如： SELECT name FROM person_tbl WHERE name REGEXP &#39;^[aeiou]|ok$&#39;; ALTER 使用 ALTER TABLE testalter_tbl DROP i; 删除一列 ALTER TABLE testalter_tbl ADD i INT; 增加一列 ALTER TABLE testalter_tbl ADD i INT FIRST; 在指定位置增加一列 ALTER TABLE testalter_tbl ADD i INT AFTER c; 在指定位置增加一列 ALTER TABLE testalter_tbl MODIFY c CHAR(10); 修改字段类型 ALTER TABLE testalter_tbl CHANGE j j INT; 修改字段名以及类型 ALTER TABLE testalter_tbl -&gt; MODIFY j BIGINT NOT NULL DEFAULT 100; 设置默认值和NOT NULL ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000; 修改字段默认值 ALTER TABLE testalter_tbl ALTER i DROP DEFAULT; 删除字段默认值 ALTER TABLE testalter_tbl RENAME TO alter_tbl; 更改表名 Use mysql on mac install by homebrew: brew install mysql start up mysql by homebrew brew services start mysql Verify the installed MySQL instance : mysql -V Reference http://blog.csdn.net/chinacodec/article/details/5797127/ http://www.runoob.com/mysql/mysql-create-database.html http://www.runoob.com/java/java-mysql-connect.html https://gist.github.com/nrollr/3f57fc15ded7dddddcc4e82fe137b58e]]></content>
      <categories>
        <category>summary</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tmux Summary]]></title>
    <url>%2F2017%2F09%2F23%2FTmuxNotes%2F</url>
    <content type="text"><![CDATA[Tmux Basic OperationEnter Session tmux to enter tmux and start a unnamed session tmux new -s demo to enter tmux and start a session named demo tmux a tmux attach the first session tmux a -t demo to attach the session named demo tmux ls to show all sessions. Show Shortcut Keys and Commands tmux list-keys to show all shortcut keys tmux list-commands to show all tmux commands crtl + b + ? to list all tmux shortcut keys, press q to return Exit Tmux crtl + b + d, detach to exit tmux, tmux is still running in background. tmux kill-session -t demo kill session whose name is demo tmux kill-server kill all sessions. Other Basic Operations ctrl + b + t, to show the time. crtl + b + : to enter command mode. ctrl + b + [ to enter copy mode, enter q to exit. Tmux Session Operation ctrl + b + : new -s session_name to create new session with name session_name ctrl + b + s to list all sessions. ctrl + b + $ to rename cuurrent session name. Tmux Window Operation ctrl + b + c to new a window ctrl + b + &amp; to close current window, need to input y to confirm ctrl + b + 0-9 to switch window ctrl + b + w to show all windows in the current session Tmux Pane Operation ctrl + b + &quot;to add vertical pane. ctrl + b + % to add horizontal pane ctrl + b + 方向键 上下左右切换pane ctrl + b + x close current pane, need to input y ctrl + b + z to maxmize current pane, and return to its original size if try again Todo Tmate tmux config Reference reference1 reference2 reference3]]></content>
      <categories>
        <category>summary</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>summary</tag>
        <tag>linux</tag>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Shell Summary]]></title>
    <url>%2F2017%2F09%2F03%2FlinuxShellSummary%2F</url>
    <content type="text"><![CDATA[Linus Shell Summary查看端口使用情况：sudo lsof -i:8888 若要停止使用这个端口的程序，使用kill +对应的pid即可 Copy Public Key :ssh-agent //启动 ssh-agent，大家可以自行搜索自己所使用OS启动 ssh-agent的方式。 ssh-add ssh-add -l // 检查自己的私钥是否被ssh-agent管理 执行以下命令，将本地public-key添加到的authorized_keys里面： ssh-copy-id -i ~/.ssh/id_rsa.pub User@HostName 查找gz文件中的logzgrep zcat zgrep 60a3b7146b12 laindocker.log-20170506.gz &gt; ~/T1836-all 从服务器上 (下载|上传) 文件到本地 下载： scp xxx@gpu:/home/src /home/drc 若是目录的话， 加 -r 上传： scp -r /localpath xxx@gpu:remotePath ubuntu soft link文件夹建立软链接（用绝对地址） ln -s 源地址 目的地址 比如我把linux文件系统rootfs_dir软链接到/home/xxx/目录下 ln -s /opt/linux/rootfs_dir /home/xxx/rootfs_dir 查看系统版本cat /etc/issue WC Notes wc -l test.txt 查看文件行数 wc -w test.txt 查看文件字数，一个字被定义为由空白、跳格或换行字符分隔的字符串。 wc -c test.txt 统计字节数| wc -m test.txt 统计字符数 wc -L test.txt 打印最长的一行的长度 查看文件夹下所有文件夹所占空间大小 sudo du -h --max-depth=1s Mac 查看端口占用并kill掉相关进程 查看端口终端输入：lsof -i tcp:port 将port换成被占用的端口(如：8086、9998)将会出现占用端口的进程信息。 kill进程找到进程的PID,使用kill命令：kill PID（进程的PID，如2044），杀死对应的进程 查看文件若干行 head -n 1 file.txt]]></content>
      <categories>
        <category>summary</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Summary]]></title>
    <url>%2F2017%2F09%2F03%2FgitSummary%2F</url>
    <content type="text"><![CDATA[Git summarygit reset –hard未commit的chagne会随着branch的切换而移动，因此，当在某一个branch中git reset --hard的时候， changes就会消失。 git 删除remote branchgit push origin --delete branch_name git rm files in repogit rm --cache files show git track filesgit ls-files git diff one file in two different commit ids:git diff HEAD(^^)(two commits before current) commit_id XX.javagit diff HEAD^^ HEAD main.c Git RSA key fingerprintThe newer SSH commands will list fingerprints as a SHA256 Key. For example ssh-keygen -lf ~/.ssh/id_rsa.pub1024 SHA256:19n6fkdz0qqmowiBy6XEaA87EuG/jgWUr44ZSBhJl6Y (DSA) If you need to compare it against a old fingerprint you also need to specify to use the md5 fingerprint hashing function. ssh-keygen -E md5 -lf ~/.ssh/id_rsa.pub2048 MD5:4d:5b:97:19:8c:fe:06:f0:29:e7:f5:96:77:cb:3c:71 (DSA) Git submodule:Git submodule delete: Delete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config. Run git rm –cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule Commit git commit -m “Removed submodule “ Delete the now untracked submodule files rm -rf path_to_submodule]]></content>
      <categories>
        <category>summary</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>linux</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 命令行快捷键]]></title>
    <url>%2F2016%2F12%2F21%2FlinuxCmdNotes%2F</url>
    <content type="text"><![CDATA[常用快捷键 Ctrl + a 光标移动到行首 Ctrl + e 光标移动到行尾 Ctrl + l 清屏 Ctrl + Shift + c 复制 Ctrl + Shift + v 粘贴 Ctrl + r 逆向搜索命令历史 Ctrl + c 终止命令 Ctrl + z 挂起命令 Ctrl + u 删除光标左边所有元素 Ctrl + k 删除光标右边所有元素]]></content>
      <categories>
        <category>ubuntu notes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim Notes]]></title>
    <url>%2F2016%2F11%2F21%2Fvim2%2F</url>
    <content type="text"><![CDATA[多行编辑用vim进行多行编辑是十分方便的，只需要以下步骤： Ctrl-v 进入纵向编辑模式 通过Shift-g, gg, j,k等选择要编辑的行 若要删除多行，则d即可; 若要编辑多行的内容，Shift-i进入INSERT模式 进行编辑，然后按两次ESC就会发现多行编辑完成。 分屏在使用vim编辑器的时候，结合vim的分屏功能，可以使得编辑更加高效： 进入分屏的几种方式： vim -On file1 file2 将file1和file2进行垂直分屏 vim -on file1 file2 将file1 和file2进行水平分屏 vim file 然后通过： Ctrl-w s对当前文件进行水平(上下)分屏 Ctrl-w v对当前文件进行垂直(左右)分屏 :sp newFile 打开新的文件，上下分割 :vsp newFile 打开新的文件，左右分割 分屏的切换： Ctrl-w j 切换到下边的分屏上 Ctrl-w k 切换到上边的分屏上 Ctrl-w h 切换到左边的分屏上 Ctrl-w l 切换到右边的分屏上 分屏的关闭： Ctrl-w c 关闭当前分屏 Ctrl-w q 关闭当前分屏，若为最后一个分屏，则退出vim. 用分屏是很方便的，当用:sp newFile打开一个新的文件时，可通过y, p的方式进行复制、粘贴，大大提高效率。 vim delete part of lines:%s/&quot;: {// delete the whole line satisfied with the pattern::g/^9 /d]]></content>
      <categories>
        <category>vim notes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim Notes]]></title>
    <url>%2F2016%2F10%2F21%2FvimNotes%2F</url>
    <content type="text"><![CDATA[Lesson 1 SUMMARY: The cursor is moved using either the arrow keys or the hjkl keys: h(left) , j (down) , k (up) , l (right) To start Vim from the shell prompt type: vim FILENAME &lt;ENTER&gt; To exit Vim type: &lt;ESC&gt; :q! &lt;ENTER&gt; to trash all changes. OR type: &lt;ESC&gt; :wq &lt;ENTER&gt; to save the changes. To delete the character at the cursor type: x To insert or append text type: i type inserted text &lt;ESC&gt; insert before the cursor A type appended text &lt;ESC&gt; append after the line NOTE: Pressing will place you in Normal mode or will cancel an unwanted and partially completed command. Lesson 2 SUMMARY: To delete from the cursor up to the next word type: dw To delete from the cursor to the end of a line type: d$ To delete a whole line type: dd To repeat a motion prepend it with a number: 2w The format for a change command is: operator [number] motion, where: 1). operator: is what to do, such as d for delete 2). [number]: is an optional count to repeat the motion 3). motion : moves over the text to operate on, such as w (word), $ (to the end of line), etc. To move to the start of the line use a zero: 0 To undo previous actions, type: u (lowercase u) To undo all the changes on a line, type: U (capital U) To undo the undo’s, type: CTRL-R Lesson 3 SUMMARY: To put back text that has just been deleted, type p . This puts the deleted text AFTER the cursor (if a line was deleted it will go on the line below the cursor). To replace the character under the cursor, type r and then the character you want to have there. The change operator allows you to change from the cursor to where the motion takes you. e.g., type ce to change from the cursor to the end of the word, c$ to change to the end of a line. The format for change is: c [number] motion Lesson 4 SUMMARY: CTRL-G displays your location in the file and the file status. G moves to the end of the file. number G moves to that line number. gg moves to the first line. Typing / followed by a phrase searches FORWARD for the phrase. Typing ? followed by a phrase searches BACKWARD for the phrase. After a search type n to find the next occurrence in the same direction or N to search in the opposite direction. CTRL-O takes you back to older positions, CTRL-I to newer positions. Typing % while the cursor is on a ( , ),[ , ],{ , or } goes to its match. To substitute new for the first old in a line type :s/old/new To substitute new for all ‘old’s on a line type :s/old/new/g To substitute phrases between two line #’s type :#,#s/old/new/g To substitute all occurrences in the file type :%s/old/new/g To ask for confirmation each time add ‘c’ :%s/old/new/gc Lesson 5 SUMMARY: :!command executes an external command, and some useful examples are: MS-DOS Unix effect :!dir :!ls shows a directory listing. :!del FILENAME :!rm FILENAME removes file FILENAME. :w FILENAME writes the current Vim file to disk with name FILENAME. v motion :w FILENAME saves the Visually selected lines in file FILENAME. :r FILENAME retrieves disk file FILENAME and puts it below the cursor position. :r !dir reads the output of the dir command and puts it below the cursor position. Lesson 6 SUMMARY： Type o to open a line BELOW the cursor and start Insert mode. Type O to open a line ABOVE the cursor. Type a to insert text AFTER the cursor. Type A to insert text after the end of the line. The e command moves to the end of a word. The y operator yanks (copies) text, p puts (pastes) it. Typing a capital R enters Replace mode until &lt;ESC&gt; is pressed. Typing “:set xxx” sets the option “xxx”. Some options are: 1) ‘ic’ ‘ignorecase’ ignore upper/lower case when searching 2) ‘is’ ‘incsearch’ show partial matches for a search phrase 3) ‘hls’ ‘hlsearch’ highlight all matching phrases 4) You can either use the long or the short option name. Prepend “no” to switch an option off: :set noic Lesson 7 SUMMARY： Type :help or press &lt;F1&gt; or &lt;Help&gt; to open a help window. Type :help cmd to find help on cmd . Type CTRL-W CTRL-W to jump to another window Type :q to close the help window Create a vimrc startup script to keep your preferred settings. When typing a : command, press CTRL-D to see possible completions. Press &lt;TAB&gt; to use one completion.]]></content>
      <categories>
        <category>vim notes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Recommended Books]]></title>
    <url>%2F2016%2F09%2F15%2Fbooks%2F</url>
    <content type="text"><![CDATA[机器学习 机器学习 by 周志华: 周志华老师的这本书非常适合作为机器学习入门的书籍，书中的例子十分形象且简单易懂。 统计机器学习 by 李航：李航老师的这本书偏优化和推倒，推倒相应算法的时候可以参考这本书。 PRML by Christopher Bishop: PRML这本书有点偏Bayesian了，初学者看起来可能有些困难，可以和前两本结合起来看。 GPCA by Yi Ma: 这本书由马毅老师耗时十年精心打造，推荐阅读。 Machine Learning A Probabilistic Perspective by Kevin P. Murphy: MLAPP这本书也是一本比较经典的机器学习书，可以和PRML互相补充着来看。 自然语言处理 数学之美 by 吴军：吴军老师的这本书适合作为入门自然语言处理的科普读物。 统计自然语言处理 by 宗成庆：中文版的自然语言处理图书是比较少的，这本书由中科院宗成庆老师所写，推荐初学者先阅读此书。 Foundations of Statistical Natural Language Processing by Christopher D. Manning: 本书由Manning大神所写，在1999年出版，最近比较火的Deep Learning for NLP没有涉及，不过可以参考他的学生Socher开的这门课 CS224n - Natural Language Processing with Deep Learning. Speech and Language Processing by Dan Jurafsky: 这本书第三版已经更新一部分章节了，书中介绍了deep learning for nlp方面的技术，推荐阅读。 To be continued.]]></content>
      <categories>
        <category>books</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Natural Language Processing</tag>
        <tag>Artificial Intelligence</tag>
        <tag>Data Mining</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ensemble Learning]]></title>
    <url>%2F2016%2F06%2F15%2FML9%2F</url>
    <content type="text"><![CDATA[Introduction集成学习 (ensemble learning) 通过组合多个学习器来完成学习任务。相比于单个学习器，通过集成学习得到的模型往往可以取得更好的performance。因此在天池、kaggle和ImageNet等各大竞赛中，最终的模型往往都是通过集成学习得到的。 集成学习并不能保证集成后的模型一定比单个的模型效果好。如果各个学习器比较接近，那么集成后的模型不会有太多performance上的提升；如果各个学习器完全相同，那么集成后的模型不会有性能的提升。所以要想获得好的集成效果，需要各个学习器准确性不能太差，同时要有多样性，即“好而不同”。然而准确性和多样性本身就存在冲突。一般来说，准确性很高之后，要增加多样性就要牺牲准确性。所以如何产生并结合“好而不同”的学习器，也是集成学习研究的核心内容。 那么怎样将各个学习器组合起来呢？对于分类任务来讲，最简单的方法就是投票；对于回归任务来讲，可以通过加权平均的方式来组合各个学习器。那么有没有更好的做法呢？Boosting, bagging 和 random forest是常用的集成学习算法，看完下文对它们的介绍，相信你会有了答案。 BoostingBoosting是一种可将弱学习器提升为强学习器的算法。通常boosting的做法是：首先在原始数据上训练出一个基学习器；用这个基学习器来改变数据的分布，即增大在训练中出错样本的权重，使得出错的样本在后续的训练中受到更大的关注；减小未出错样本的权重；然后在调整分布后的样本训练集上训练新的基学习器；如此重复进行，直到基学习器的数量达到了预先设定的个数\(T\)，最终将这\(T\)个基学习器进行加权组合。 Boosting中最著名的代表就是adaboost (adaptive boosting)算法了： Adaboost输入：数据集 \(D = \{(x_i, y_1), (x_2, y_2), …, (x_n, y_n) \} \), 基学习算法 \(L\)，训练轮数\(T\). 输出：集成后的学习器 \(H(x)\) 步骤： 初始化训练数据权值分布：\(W_1 = \{ w_{11}, w_{12}, …, w_{1n} \}\), \(w_{1i} = \frac{1}{n}\), i = 1,2,3…n for \(t = 1 : T\) do: 在分布为\(W_t\)的训练集上训练基学习器 \(h_t = L(D, W_t) \) 计算基学习器 \(h_t\)在训练数据上的错误率：\(e_t = \sum_{i = 1}^{n} w_{ti} \ I(h_t(x_i) \neq y_i)\), 其中\(I\) 为 indicator function。 计算基学习器加权系数：\(\alpha_{t} = \frac{1}{2} \ \ln\frac{1 - e_t}{e_t}\)。 当\(e_t \leq \frac{1}{2} \)时，\(e_t\)越小， 加权系数\(\alpha_t \)越大，在最终的模型中起的作用就越大。 if \(e_t &gt; 0.5\), then break; 更新训练数据权值分布： \(W_{t+1} = \frac{W_t \exp{(-\alpha_t f(x) h_t(x))}}{Z_t}\), 其中\(Z_t\)为normalization factor。 展开来看有：若训练正确，则权重减小： \(w_{t+1, i} = \frac{w_{t,i} \exp{(-\alpha_t)}}{Z_t}\)； 若训练错误，权重增大： \(w_{t+1, i} = \frac{w_{t,i} \exp{(\alpha_t)}}{Z_t}\) end for \(H(x) = sign(\sum_{t = 1}^{T} \alpha_t h_t(x))\), 其中\(sign(x)\) 为符号函数。 Adaboost 算法解释Adaboost算法还有另一种解释，即认为损失函数为指数函数\(E = \sum_{i = 1}^{n} \exp{(-\frac{1}{2} y_i \ F(x_i))}\), 其中 \(F(x) = \sum_{t = 1}^{T} \alpha_t h_t(x)\)， 需要求的参数是\(\alpha_t\)和各个基学习器中的参数。对于第\(m\)个基学习器来说，我们可以认为前\(m-1\)个基学习器是fixed的，所以可以通过优化损失函数来求得\(\alpha_m\)和\(h_m(x)\)中的参数。具体细节可以查看PRML中的659-663页。 BaggingRandom ForestKNNDecision TreeReference Book: Pattern Recognition and Machine Learning by Christopher Bishop Notes of machine learning by Andrew Ng in cousera 机器学习 周志华 Slides by Prof. Wang 统计学习方法 GPCA by Yi Ma)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Ensemble Learning</tag>
        <tag>Boosting</tag>
        <tag>Bagging</tag>
        <tag>Random Forest</tag>
        <tag>KNN</tag>
        <tag>Decision Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clustering]]></title>
    <url>%2F2016%2F05%2F15%2FML8%2F</url>
    <content type="text"><![CDATA[Clustering聚类 (clustering)是机器学习中经常会涉及到的一个task。通常来讲，它是一种unsupervised task，通过挖掘数据内部的结构等信息，来将数据划分成若干部分，也有利用数据的label信息来做辅助的方法，如Learning Vector Quantization (LVQ)。 K-means提到聚类，最常用的方法就是K-means了。K-means的思想比较简单：对于一组数据，我们希望找到一组中心点，使得整个数据集中所有点到离它最近的中心点的距离之和最小，相应的数学表达式为： $$ E = \sum_{i=1}^{k}\sum_{x \in C_i} ||x - \mu_i||_2^2$$ 其中，\(k\)为簇的总数，\(C_i\)为相应的第\(i\)个簇。若直接对\(E\)进行求解很困难(NP-hard)，因为有指数多个可能的簇划分。所以这里采用迭代优化的方法来近似求解。 K-means首先初始化k个中心点，这里需要提到的是k-means的初始化对最终结果有着很大的影响，不同的初始化会有着不同的聚类效果。 对数据集中的所有点，找到距离它最近的中心点，这样就得到了新的簇的划分。相应的数学表达式为：\(i = \arg\min_{i=1,2,…,k} ||x - \mu_i||_2^2\) 在新形成的k个簇中，更新k个相应的中心点。相应的数学表达式为：\(\mu_i = \frac{\sum_{x \in C_i} \ x} {|C_i|}\)。 重复步骤2和步骤3直到达到迭代次数或者收敛 (E的值变化很小)。 k-means中存在的两个问题k-means中有两个问题需要值得注意： k-means中的中心点怎么初始化 k-means中的k怎么选取 k-means中心点初始化对于中心点的初始化，我们希望初始化的中心点能在数据点附近，同时中心点尽量分散开。 如果中心点初始化的比较近的话，很有可能就都初始化在同一个簇中，这样就使得原本应该划分为同一个簇的数据点被划分成了两个簇。 通常的做法有： 随机初始化中心点到数据集上的k个点上。然后跑若干次，选取其中\(E\)最小的那一组初始化。这种做法的缺点在于，有可能两个中心点离的很近。 首先随机初始化一个中心点到数据集上的一个点上，第二个中心点初始化为距离第一个中心点最远的那个数据点；对于后面的中心点的初始化，我们每次初始化成所有数据点中距离前面初始化好的中心点最近距离最大的那个点。 用k-means++方式来初始化。k-means++的初始化方法与第二种方法比较像，不同之处在于k-means+＋引入了概率，即每一个数据点成为下一个中心点的概率正比于该数据点与其最近中心点距离的平方\(D(x)^2\)。 k-means中的k怎么选取当k取值越大时，相应的E会越来越小，如果k取为数据点的总数，那么E会变成0。所以单独的E不能作为k选取的标准。一种解决方法是用\(E+complexity\)来作为衡量的标准，其中complexity与k的大小有关，k越大，相应的complexity越大。常用的衡量标准有 BIC (Bayesian Information Criterion)。还有一个在聚类中经常用到的衡量标准：CH (Calinski-Harabasz) index，有兴趣的读者可以自行google，这里不做具体介绍了。 Canopy + Kmeans: 将Canopy和Kmeans结合起来使用，可以不用预先定义K，在hadoop等工具中已经有相关算法实现。 Mixtures of Gaussiansk-means 在某种条件下，可以看作是mixtures of Gaussians的特例。在k-means中，我们认为每一个数据点必须属于某一个簇，这个条件太硬(hard)了， 在mixtures of Gaussians中，我们认为每一个数据点按照某个概率属于某一个簇。 Introduction数据通常满足一定的分布，对于比较简单且满足高斯分布的数据，我们可以用一个高斯分布来对这些数据来建模。然而，现实中数据的分布通常比较复杂，只用一个高斯分布建模效果不好，通常用若干个高斯分布的组合来建模数据的分布，这里我们用K个高斯分布的组合来建模数据的分布： $$p(\mathbf{x}) = \sum_{k = 1}^{K} \pi_{k} N(\mathbf{x}|\mu_{k}, \Sigma_{k})$$ 其中\(\pi_{k}\)为高斯分布\(N(\mathbf{x}|\mu_{k}, \Sigma_{k})\)的加权系数。 Hidden Variables我们引入一个K维的hidden variable \(\mathbf{z}\)， \(\mathbf{z}\)是一个one-hot的向量，用来建模当前的变量\(\mathbf{x}\)由哪一个高斯分布生成的 (知道这个信息后，模型的表示和参数求解都会变得简单)，相应的， $$p(\mathbf{x}) = \sum_{\mathbf{z}} p(\mathbf{z}, \mathbf{x}) = \sum_{\mathbf{z}} p(\mathbf{z}) p(\mathbf{x}|\mathbf{z}) ＝\sum_{k = 1}^{K} \pi_{k} N(\mathbf{x}|\mu_{k}, \Sigma_{k})$$ Cost FunctionMixtures of Gaussians是生成模型，我们用maximum likelihood estimation (MLE)来求得我们的优化目标，即： $$ \log L(\mathbf{\pi}, \mathbf{\mu}, \mathbf{\Sigma}) = \log(\prod_{i = 1} ^ {N} \sum_{k = 1}^{K} \pi_{k} N(\mathbf{x}_{i}|\mu_{k}, \Sigma_{k})) = \sum_{i = 1}^{N} \log(\sum_{k = 1}^{K} \pi_{k} N(\mathbf{x}_{i}|\mu_{k}, \Sigma_{k})) $$ 模型的参数为\(\mathbf{\pi}, \mathbf{\mu}, \mathbf{\Sigma}\), 我们通过优化目标函数来求得最优的参数值。那么如果有了学好的模型，我们怎么做prediction呢？我们可以通过计算\(p(z_k = 1 | \mathbf{x})\) 的概率，然后将点\(\mathbf{x}\)划分到概率最大的那个簇，相应的：$$ p(z_k = 1 | \mathbf{x}) = \frac{p(z_k = 1) p(\mathbf{x}|z_k = 1)}{p(\mathbf{x})} = \frac{\pi_k N(\mathbf{x}|\mu_{k}, \Sigma_{k})}{\sum_{k = 1}^{K} \pi_k N(\mathbf{x}|\mu_{k}, \Sigma_{k})}$$ 接下来的问题就是怎么优化目标函数来求得最优参数的值了，对于含有隐变量的优化问题，我们通常用Expectation Maximization (EM)来求解。 Expectation Maximization (EM)EM算法是一种常用的优化算法，多用在含有隐变量的优化问题上。通过MLE，我们可以得到相应的优化目标，即： $$ \log L(\mathbf{\theta}) = \log \prod_{i = 1}^{N} p(\mathbf{x}) = \sum_{i = 1}^{N} \log p(\mathbf{x}) = \sum_{i = 1}^{N} \log \sum_{\mathbf{z}}p(\mathbf{x}, \mathbf{z}) = \sum_{i = 1}^{N} \log \sum_{\mathbf{z}}p(\mathbf{x}, \mathbf{z}) $$ 由于对数函数为凹函数，则由Jesen不等式，我们可以得到： $$\log L(\mathbf{\theta}) = \sum_{i = 1}^{N} \log \sum_{\mathbf{z}_i}p(\mathbf{x}_i, \mathbf{z}_i) = \sum_{i = 1}^{N} \log \sum_{\mathbf{z}_i}Q(\mathbf{z}_i) \frac{p(\mathbf{x}_i, \mathbf{z}_i)}{Q(\mathbf{z}_i)} \geq \sum_{i = 1}^{N} \sum_{\mathbf{z}_i}Q(\mathbf{z}_i) \log \frac{p(\mathbf{x}_i, \mathbf{z}_i)}{Q(\mathbf{z}_i)} $$ 其中，\(Q(\mathbf{z}_i)\) 为关于隐变量\(\mathbf{z}_i\)的一个分布。经过放缩后，对于任意一个\(Q(\mathbf{z}_i)\)，我们都可以得到目标函数的一个下界，那么怎么选取\(Q(\mathbf{z}_i)\)呢？对于特定的参数\(\mathbf{\theta}\), 我们可以选取\(Q(\mathbf{z}_i)\), 使得上述不等式关系中的相等关系成立。由Jesen不等式可知，当且仅当\(E(f(x)) = f(E(x))\), 等式成立，即 \(\frac{p(\mathbf{x}_i, \mathbf{z}_i)}{Q(\mathbf{z}_i)} = c\), 相应的，\(Q(\mathbf{z}_i) \propto p(\mathbf{x}_i, \mathbf{z}_i)\). 又由\(\sum_{\mathbf{z}_i} Q(\mathbf{z}_i) = 1\), 得到\( Q(\mathbf{z}_i) = p(\mathbf{z}_i | \mathbf{x}_i, \theta)\). 由此得到EM算法: 首先我们初始化参数\(\theta\), 然后经过E-step 和 M-step若干次迭代，直到收敛。 E-step: For each i, set $$ Q(\mathbf{z}_i) = p(\mathbf{z}_i | \mathbf{x}_i, \theta) $$ M-step, set: $$ \theta = \arg \max_{\theta} \sum_{i = 1}^{N} \sum_{\mathbf{z}_i}Q(\mathbf{z}_i) \log \frac{p(\mathbf{x}_i, \mathbf{z}_i)}{Q(\mathbf{z}_i)} $$ ConvergenceEM算法一定会收敛吗？答案是肯定的。因为在E-step中，\(\log L(\theta)\)等于其下界的值；在M-step中，我们最大化下界来获得新一轮的参数\(\theta\). 然后在下一次的E-step中，\(\log L(\theta)\)又等于新的下界的值。所以在EM算法中，优化目标是不断变大的。但是EM算法只能保证局部收敛；如果优化目标是凸函数，则可以得到全局最优解。 Mixture of Gaussians revisited有了上面EM的推倒，相信现在可以轻易的推出Mixture of Gaussians中参数更新的公式了： E-step: $$ \gamma_{k} = p(z_k = 1 | \mathbf{x}) = \frac{\pi_k N(\mathbf{x}|\mu_{k}, \Sigma_{k})}{\sum_{k = 1}^{K} \pi_k N(\mathbf{x}|\mu_{k}, \Sigma_{k})}$$ M-step: $$\mu_{k} = \frac{\sum_{i=1}^{N}\gamma_k \mathbf{x}_i}{\sum_{i=1}^{N}\gamma_k}$$ $$ \pi_k = \frac{\sum_{i = 1}^{N} \gamma_k}{N}$$ \(\Sigma_k\)可以用相似的方法来计算，这里需要注意的是在计算\( \pi_k\)最优值的时候，需要用拉格朗日来解等式约束。 Spectral Clustering &amp;&amp; N-cutIn most cases, the distribution of a mixed dataset can be more complicated than simply clustering around a few cluster centers. In this case, the K-means and mixtures of Gaussians may not group the data correctly. The following figure gives an example where the K-means and mixtures of Gaussians may not group the data correctly. 一种解决上述问题的方法是将数据点经过某个合适的非线性变换 (e.g., Laplacian Eigenmaps) ，转换到合适的形式 (例如上面图中的例子)。 Spectral clustering和 Normalized cut (N-cut)算法就是应用了这种思想。关于这两个算法的细节这里不再详细列出，有兴趣的读者可以去看马毅老师的新书GPCA by Yi Ma)。 Hierarchical Clustering (层次聚类)层次聚类试图在不同层次上来对数据进行划分，进而形成树形的聚类结构。它对数据的划分是一个“自底向上”的过程。该算法的思想也比较简单： 数据集中的每一个样本为一个初始簇 将距离最近的两个簇合并 不断重复步骤2，直到簇的个数达到指定的个数为止。 距离的衡量方式有以下几种： 两个簇中所有点间距离的最小值 两个簇中所有点间距离的最大值 两个簇的中心点之间的距离 两个簇中所有点间距离的平均值 Other MethodsDensity-based Clustering密度聚类是通过样本数据分布的紧密程度来划分数据的，在这里我们主要介绍DBSCAN算法： DBSCAN算法先找出数据集中各样本的\(\epsilon\)-邻域, 并确定核心对象集合\(\Omega\) 从核心对象集合\(\Omega\)中选取一个核心对象作为种子，找出由它密度可达的所有样本，这就构成了一个聚类簇。 然后从\(\Omega\)集合中去除步骤2中的核心对象 重复步骤2和3直到\(\Omega\)为空。 这个算法中涉及到的相关概念可以参考周志华老师机器学习这本书。 Learning Vector Quantization (LVQ)LVQ和其他聚类方法不同，LVQ假设数据有类别标记，并利用样本的类别标记信息来辅助聚类： LVQ的目标是学得一组n维原型向量\(\{p_1, p_2,…p_q \} \), 每个原型向量用来代表一个聚类簇，簇标记\(t_i \in \Lambda\) 初始化原型变量，并为各个原型变量预设标记\(t_i\) 从数据集中随机选取一样本，并找到和该点距离最近的原型向量。 如果该样本点和原型向量的类别标记相同，则使该原型向量靠近该样本点一些，否则远离该样本点一些。 重复步骤3和4直到收敛。 有了学好的一组原型向量\(\{p_1, p_2,…p_q \} \)，在做inference的时候，我们通过找距离test样本距离最近的原型向量，来得到该test样本点所属的簇。LVQ通常用来改变类别标记的颗粒度大小，例如，如果想使类别标记的更细一些，则可以使原型向量的个数大于原来类别标记种类的数量。 更多细节可以参考周志华老师新书：机器学习。 Applications聚类有很多的应用场景，例如在图像压缩中，通过存储图像聚类后的中心点来进行图像压缩；聚类也常用来进行异常检测 (离群点检测)，可将远离所有簇中心的样本作为异常点，或将密度极低处的样本作为异常点。 Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop Notes of machine learning by Andrew Ng in cousera 机器学习 周志华 Slides by Prof. Wang 统计学习方法 GPCA by Yi Ma)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Clustering</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Support Vector Machines]]></title>
    <url>%2F2016%2F05%2F09%2FML7%2F</url>
    <content type="text"><![CDATA[Support Vector MachinesIntroduction在logistic regression中，分类器只要将两个类别的点分开即可使cost function达到最小，但是哪一种分类器更好呢？下面的三个logistic regression分类器都能将两个类别的点完全分开。从图中我们可以直观的看出，距离分离平面越近的点越容易分类错误，而距离分离平面越远的点则越不容易分类错误。下面三幅图中，图三中的点最不容易分类错误。所以我们想使所有的点分类正确，同时所有的点距离分离平面尽可能的远，可以理解为我们要最大化所有点中到分类平面的最小距离, 这也是SVM的目标。 我们知道点\(x_i\)到分类平面的几何距离为\(\frac{|w^Tx_i+b|}{||w||}\),而如果该平面能够作为分类平面，则必有：\(y_i(w^Tx_i+b) &gt; 0\). 我们的目标是最大化所有点到分离平面的最小距离。通过rescaling \(w,b\),可以得到: \(\min_{i = 1,2,…m} y_i(w^Tx_i + b) = 1 \) (这个地方可能不是很好理解，需要注意的是：1.平面的w和b可以变化到相应的倍数而这个平面仍然保持不变；2.假设当前的w和b使得距离分类平面最近的点的\(y(w^Tx + b) = D\), 则我们可以将w和b缩小\(\frac{1}{D}\),从而使\(y(w^Tx + b) = 1\).),这样我们可以得到所有点中到分离平面的最小距离为: \(\frac{1}{||w||}\), 我们把这个值称为margin。由此，我们可以得到SVM的优化目标和限制条件： $$ \max_{w,b} \ \ \frac{1}{||w||} \\ s.t. \ \ y_i(w^Tx_i + b) \geq 1$$相应地，可以变为， $$ \min_{w,b} \ \ \frac{1}{2}||w||_{2}^{2} \\ s.t. \ \ y_i(w^Tx_i + b) \geq 1$$ 由此，SVM的目标函数就变成了一个标准的凸二次规划问题，有很多开源的优化包都可以用来解这个问题。Here is an example using the active set optimization method in matlab (first you need to transform the equations into vector form): 12345678910111213141516171819202122232425X = [ 3 1; 3 -1; 6 1; 6 -1; 1 0 ; 0 1; 0 -1; -1 0];y = [1 1 1 1 -1 -1 -1 -1]';%% plot the data:plot(X(1:4,1),X(1:4,2),'+')hold onplot(X(5:8,1),X(5:8,2),'o')hold on%% primal problem:w = [0 0]';wb = 0;theta = [wb;w];H = [0 0 0; 0 1 0; 0 0 1];f = [0 0 0]';b = -1*ones(size(X,1),1);A = -1*[y, [y,y].*X];options = optimoptions('quadprog',... 'Algorithm','active-set','Display','off');[theta,fval,exitflag,output,lambda] = ... quadprog(H,f,A,b,[],[],[],[],[],options);wb = theta(1);w = theta(2:end);X*w + wb Dual Problem of SVM更常用的求解SVM的方法是求解其对偶问题。 首先我们可以将优化目标写成拉格朗日函数的形式：\(L(w,b,\alpha) = \frac{1}{2}w^Tw + \sum_{i=1}^{m}\alpha_i(1-y_i(w^Tx_i+b))\), 相应的与约束条件等价的形式为: \(\max_{\alpha_i &gt; 0} L(w,b,\alpha)\)。那么关于SVM，我们可以表示为：\(\min_{w,b} \max_{\alpha_i &gt; 0} L(w,b,\alpha)\). 由于上述表达式属于强对偶的形式，所以原问题的解即为对偶问题的解。由此，我们可以得到SVM的对偶问题为： $$ \max_{\alpha} \min_{w,b} L(w,b,\alpha) ＝ \max_{\alpha} \min_{w,b} \frac{1}{2}w^Tw + \sum_{i=1}^{m}\alpha_i(1-y_i(w^Tx_i+b))$$ 首先，求解该拉格朗日函数关于\(w,b\)的最小值的解，对\(L(w,b,\alpha)\) 对\(w,b\)求偏导可得， $$\frac{\partial L}{\partial w} = w － \sum_{i=1}^{m} \alpha_ix_iy_i ＝ 0$$ $$\sum_{i=1}^{m}\alpha_iy_i = 0$$ 将相应的\(w,b\)带入可得对偶问题的优化目标为： $$\max_{\alpha} L(w,b,\alpha) = -\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_jx_i^Tx_j + \sum_{i=1}^{m} \alpha_i$$ 相应的对偶问题的约束条件为： $$\alpha_i \geq 0 \\ \sum_{i=1}^{m}\alpha_iy_i = 0$$ 对偶问题依然是一个凸二次规划问题，可以用常用的优化包来求解。这样在求得最优的\(\alpha^{*}\)之后，通过\(w^{*} = \sum_{i=1}^{m} \alpha^{*}_ix_iy_i\)即可求得相应的最优w值。那么相应的b怎么求呢？我们可以看原问题的KKT条件： $$\alpha_i \geq 0 \\ 1 - y_i(w^Tx_i+b) \leq 0 \\ \alpha_i(1 - y_i(w^Tx_i+b)) = 0$$ 当\(\alpha_i &gt; 0\)时，相应的有\(y_i = (w^Tx_i+b)\), 此时的(\(x_i,y_i\))即为support vectors，最优的分类平面即由这些support vectors决定。由这些support vectors，我们可以得到: $$b^{*} = y_s - {w^{*}}^Tx_s = y_s - \sum_{i=1}^{m} \alpha^{*}_iy_ix_i^Tx_s$$ Here is an example using the optimization method in matlab to solve the dual problem of SVM (first you need to transform the equations into vector form): 1234567891011121314151617181920212223X = [ 3 1; 3 -1; 6 1; 6 -1; 1 0 ; 0 1; 0 -1; -1 0];y = [1 1 1 1 -1 -1 -1 -1]';a = zeros(size(X,1),1);f = -1*ones(size(X,1),1);lb = zeros(size(X,1),1);beq = 0;Aeq = y';G = ([y y].*X) * ([y y].*X)';options = optimoptions('quadprog',... 'Algorithm','interior-point-convex','Display','off');[a,fval,exitflag,output,lambda] = ... quadprog(G,f,[],[],Aeq,beq,lb,Inf,[],options);t = a.*y;t1 = [t t].*X;w = sum(t1)'b = y(1) - X(1,:)*w;(X*w + b) / norm(w) %predict new points:yNew = sign(w'*[3;-1] + b); Extensions of SVMsKernel Function在前面的讨论中，我们认为样本在特征空间是线性可分的，然而在现实任务中，原始样本空间不一定是线性可分的，最常见的例子就是“异或”。对于这样的问题，我们可以考虑从原始空间映射到更高维的特征空间，即将样本“升维”。 令\(\phi(x)\)为\(x\)升维后的表示，则相应形式的SVM原问题为： $$ \min_{w,b} \ \ \frac{1}{2}||w||_{2}^{2} \\ s.t. \ \ y_i(w^T\phi(x_i) + b) \geq 1$$ 对偶问题为： $$\max_{\alpha} L(w,b,\alpha) = -\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_j{\phi(x_i)}^T\phi(x_j) + \sum_{i=1}^{m} \alpha_i$$ 相应的对偶问题的约束条件为： $$\alpha_i \geq 0 \\ \sum_{i=1}^{m}\alpha_iy_i = 0$$ 可以发现在上面的等式中存在\({\phi(x_i)}^T\phi(x_j)\)的计算，然而由于升维后的空间维度可能很高，因此直接在升维后的特征空间计算内积通常是很困难的。在这里我们引入核函数(kernel function) 使得\(k(x_i,x_j) = {\phi(x_i)}^T\phi(x_j)\), 即将在升维后空间的内积转化为在原空间通过核函数计算的结果，相应的有： $$\max_{\alpha} L(w,b,\alpha) = -\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_jk(x_i,x_j) + \sum_{i=1}^{m} \alpha_i$$ 需要注意的是核函数要求其核矩阵是半正定的。常见的核函数有： 线性核：\(k(x_i,x_j) = x_i^Tx_j\) 多项式核: \(k(x_i,x_j) = (x_i^Tx_j)^d\) 高斯核: \(k(x_i,x_j) = \exp(-\frac{||x_i-x_j||^2}{2\sigma^2})\) Soft-margin SVM在前面的讨论中，我们一直假定样本空间是线性可分的，然而现实任务中往往很难确定训练样本在特征空间中是否是线性可分。解决这个问题的办法是引入软间隔的概念(soft-margin)。在之前的问题中，我们认为所有点均需满足\(y_i(w^Tx_i+b) \geq 1\), 这个间隔太硬了，我们称之为硬间隔(hard-margin). 为了解决硬间隔的问题，我们允许可以有点不满足硬间隔的条件，即\(y_i(w^Tx_i + b) \geq 1 - \xi_i\), 同时要求在最大化margin的同时，不满足硬间隔约束的点尽可能少，即\(\min_{w,b,\xi}\frac{1}{2}w^Tw + C\sum_{i=1}^{m} \xi_i\),综上可得： $$\min_{w,b,\xi} \frac{1}{2}w^Tw + C\sum_{i=1}^{m} \xi_i \\ s.t. \ \ y_i(w^Tx_i + b) \geq 1 - \xi_i \\ \xi_i \geq 0$$ 需要提到的一点是，目标函数中\(\sum_{i=1}^{m} \xi_i \) 的引入实际上采用的是hinge loss: \(\max(0,1-z)\). 对soft-margin SVM求解可以通过求其对偶问题的。soft-margin SVM相应的拉格朗日表达式为： $$L(w,b,\alpha,\xi,\mu) = \frac{1}{2}w^Tw + C\sum_{i=1}^{m} \xi_i + \sum_{i=1}^{m}\alpha_i(1-\xi_i-y_i(w^Tx_i+b)) - \sum_{i=1}^{m}\mu_i\xi_i$$ 相应的KKT条件为： $$\alpha_i \geq 0, \ \ \ \mu_i \geq 0 \\ y_i(w^Tx_i + b) \geq 1 - \xi_i \\ \xi_i \geq 0 \\ \alpha_i(1-\xi_i-y_i(w^Tx_i+b)) = 0 \\ \mu_i\xi_i = 0$$ 对\(w,b,\xi\)求偏导可得： $$w = \sum_{i=1}^{m} \alpha_ix_iy_i $$ $$\sum_{i=1}^{m}\alpha_iy_i = 0$$ $$C = \alpha_i + \mu_i$$ 得出的对偶问题形式为： $$\max_{\alpha} \sum_{i=1}^{m}\alpha_i -\frac{1}{2} \sum_{i=1}^{m}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_jx_i^Tx_j \\ s.t. 0 \leq \alpha_i \leq C \\ \sum_{i=1}^{m} \alpha_iy_i = 0$$ 若\(\alpha_i &gt; 0\) 则有 \(y_i(w^Tx_i + b) = 1 - \xi_i\), 相应的样本均为support vectors. 此时若\(\alpha_i &lt; C\), 则\(\mu_i &gt; 0\), \(\xi_i = 0\),可知该样本恰好在margin平面上；若\(\alpha_i ＝ C\), 则\(\mu_i ＝ 0\),此时若\(\xi_i &lt; 1\),可知该样本在最大间隔内部；若\(\xi_i &gt; 1\),可知该样本分类错误。 Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop Notes of machine learning by Andrew Ng in cousera 机器学习 周志华 Slides by Prof. Wang 统计学习方法]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Support Vector Machines</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercises]]></title>
    <url>%2F2016%2F04%2F26%2FML6%2F</url>
    <content type="text"><![CDATA[Part I : Data Preprocessing在实际数据中，我们总会遇到类别变量(category variables)。对于这种变量，它是没有数值意义上大小的，我们要用dummy coding来编码，然后再来处理。常用的dummy coding方法：对于有n种类别的类别变量，我们用n-1位数来编码。(例如：有四个类别种类的变量，我们用000，001，010，100来编码)。在实际数据中，经常也会出现数据缺失的情况，在这里我是用该属性(attribute)的均值来填充的(当然也可以用其他的办法来解决：比如删除有缺失属性的样本，或者将缺失的属性作为一个新的类别等). Part II: Linear Regression and Stochastic Gradient Descent (SGD)这一部分主要贴下minibatch-SGD的实现，关于Linear Regression的实现已经在前几篇博客中提过了。 1234567891011121314151617181920212223function [paraTheta,cost] = sgd(theta0,X,y)epochs = 50;minibatch = 256;m = size(X,1);alpha = 0.001;paraTheta = theta0;for i = 1: epochs rp = randperm(m); for j = 1 : minibatch : (m - minibatch + 1) x1 = X(rp(j:j+minibatch-1)',:); y1 = y(rp(j:j+minibatch-1)'); [cost,gradient] = linearRegressionCost(paraTheta,x1,y1); paraTheta = paraTheta - alpha*gradient; end alpha = alpha/2.0;cost = 0.5*norm(X*paraTheta-y);endend 1234function [cost, gradient] = linearRegressionCost(theta,X,y) cost = 0.5*norm(X*theta-y,2); gradient = X'*(X*theta - y);end Part III: Overfitting and Regularization for Regression当我们对模型参数加了L1 norm约束之后(LASSO)，模型的优化目标不再是在全部点处可导，这时basic gradient descent的方法就不再可行了。关于LASSO的一阶最优条件，在 Linear Models for Regression这篇博客中已经提过了。常用的求解LASSO的方法有：迭代软阈值算法(IST), 最小角回归(LARS), 坐标下降法(coordinate descent), ADMM 等。 迭代软阈值算法(IST)在linear regression中，我们的优化目标为\(E_{in} = \frac{1}{2} ||\mathbf{X}\theta - \mathbf{y}||_2^2 + \lambda||\theta||_{1} = f(\theta) + \lambda||\theta||_{1}\). IST算法：在点\(\theta\)处，$$ Q(z,\theta) = f(\theta) + \nabla f(\theta)^T(z - \theta) + \frac{1}{2}||z - \theta||_2^2$$ 是对\(f(z)\)的二阶近似。现在考虑我们的L1约束问题：\(\min_{\theta} f(\theta) + \lambda||\theta||_{1} \)，对第k次迭代，IST用local的\(Q(z,\theta_{k}) + \lambda ||z||_1\)来代替：\( f(\theta) + \lambda||\theta||_{1} \). 这样有：$$\theta_{k+1} = arg \min_{z} Q(z,\theta_{k}) + \lambda ||z||_1 $$ \(\theta_{k+1}\)的解的形式可以用软阈值算子来写出：\(\theta_{k+1} = S_{\lambda}(\theta_{k} - \nabla f(\theta_{k}^T)) = S_{\lambda}(\theta_{k} - \mathbf{X}^T(\mathbf{X}\theta_{k} - \mathbf{y})\). 其中， 关于软阈值算子的实现： 123function y = soft(x,tau)%This is the soft-thresholding operatory = sign(x).*max(abs(x)-tau,0); 总结：IST是一种迭代优化的方法，对于第k次迭代\(\theta_k\), IST对目标函数在\(\theta_k\)处进行展开，用目标函数的二阶近似来代替该目标函数；通过求解该二阶近似函数来得出第k+1次迭代\(\theta_{k+1}\)的值。 坐标下降法 (Coordinate Descent)Coordinate descent (CD)是一种常用的求解模型参数的方法。在每一次迭代中，CD不是沿着参数梯度方向进行搜索，而是沿着坐标方向进行搜索。对于有n个参数的linear regression问题，CD在每一次迭代中沿着一个坐标方向去搜索，通过循环使用不同坐标方向来达到目标函数的局部最小值。 \(E_{in} = \frac{1}{2} ||\mathbf{X}\theta - \mathbf{y}||_2^2 + \lambda||\theta||_{1} = f(\theta) + \lambda||\theta||_{1}\). 对第i个坐标方向进行最小化,得到一阶最优条件：$$\mathbf{X}^T_{i}(\mathbf{X}\theta - \mathbf{y}) + \lambda s_i = \mathbf{X}^T_{i} \mathbf{X}_i \theta_i + \mathbf{X}^T_{i}\mathbf{X}{-i}\theta_{-i} - \mathbf{X}^T_{i}\mathbf{y} + \lambda s_i = 0 $$ 其中，\(\mathbf{X}_i \)表示 \(\mathbf{X}\)的第i列，\(\mathbf{X}_{-i} \)表示\(\mathbf{X}\)除去第i列，\(s_i\)表示次梯度。 通过以上一阶最优条件解得： $$\theta_i = S_{\lambda / ||\mathbf{X}_i||_2^2}(\frac{\mathbf{X}_i^T (\mathbf{y} - \mathbf{X}{-i}\theta_{-i})}{\mathbf{X}_i^T \mathbf{X}_i})$$ 其中，\(i = 1,2,…n\), S为软阈值算子。 当目标函数为光滑的时候，CD通过沿着不同坐标方向不断迭代，可以收敛到局部极小值或者驻点；当目标函数不光滑的时候，CD可能会收敛到非驻点(non-stationary point). 下面是对Linear Regression问题的CD解法。 12345678910111213141516171819202122function [paraTheta, cost] = cdCost(theta0,X,y,lambda)theta = theta0;epochs = 50;n = size(X,2);optTol = 0.0001;for i = 1: epochstheta_old = theta;for j = 1:n theta(j) = softThreshold(j,theta,X,y,lambda);endcost = 0.5*norm(X*theta-y) + lambda*norm(theta,1)%% checking convergence:if sum(abs(theta-theta_old))/sum(abs(theta)) &lt; optTol break;endendparaTheta = theta;end 12345678910111213141516function [thetai] = softThreshold(i,theta,X,y,lambda)Xt = X';a = Xt(i,:)*y;c = X*theta - X(:,i)*theta(i);b = Xt(i,:)*c;den = Xt(i,:)*X(:,i);if(a-b &gt; lambda) thetai = (a-b-lambda) / den;elseif(a-b &lt; -lambda) thetai = (a-b+lambda) / den;else thetai = 0;end Part IV: Classification 关于Logistic Regression model的实现已经在Linear Models for Classification这篇博客中提过了 (用了gradient descent，Newton method，BFGS 和 l-BFGS(minfunc)四个优化方法来实现)。 Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop Notes of machine learning by Andrew Ng in cousera 机器学习 周志华 Slides by Prof. Wang 统计学习方法 Coordinate Descent]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Exercise</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Coordinate Descent</tag>
        <tag>BFGS</tag>
        <tag>Exercises</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linear Models for Classification]]></title>
    <url>%2F2016%2F04%2F24%2FML5%2F</url>
    <content type="text"><![CDATA[上一篇写了linear models for regression, 这一篇打算写linear models for classification. 当 \(y_i\) 为连续变量时，通过输入 \(\mathbf{x_i}\) 预测 \(y_i\) 为回归(regression)问题; 当 \(y_i\) 为离散变量时，通过输入 \(\mathbf{x_i}\) 预测 \(y_i\) 为分类 (classification) 问题。 Logistic RegressionLogistic regression 是一种常用的分类方法。对于二分类问题，如果要用一个线性分类器去分类的话，最简单的办法就是对输入\(\mathbf{x}\) 做线性组合\(\theta^T \mathbf{x}\), 然后将\(\theta^T \mathbf{x}\)和阈值\(\tau\)进行比较。如果大于该阈值，则为正例；否则为负例。这种和阈值进行比较的方法等效于分段函数。分段函数虽然简单，但它不连续，非凸。 Sigmoid (logistic) 函数可以作为该分段函数的替代。$$f(\theta^T\mathbf{x}) = \frac{1}{1 + e^{- \theta^T\mathbf{x}}}$$ 这样，当 \(f(\theta^T\mathbf{x}) &gt; \frac{1}{2}\)时，我们认为\(\mathbf{x}\)属于正类；当 \(f(\theta^T\mathbf{x}) &lt; \frac{1}{2}\)时，我们认为\(\mathbf{x}\)属于负类。我们把用sigmoid函数的这种方法称为 logistic regression。 关于Logistic Regression的由来:我们对 \(f(\theta^T\mathbf{x}) = \frac{1}{1 + e^{- \theta^T\mathbf{x}}} \) 进行变换可以得到：\(\log \frac{f(\theta^T\mathbf{x})}{1-f(\theta^T\mathbf{x})} = \theta^T\mathbf{x}\). 其中，\( \frac{f(\theta^T\mathbf{x})}{1-f(\theta^T\mathbf{x})}\) 称为几率(odd ratio); \(\log \frac{f(\theta^T\mathbf{x})}{1-f(\theta^T\mathbf{x})}\)称为对数几率 (log odds,or logit)。 可以看到，\(\log \frac{f(\theta^T\mathbf{x})}{1-f(\theta^T\mathbf{x})} = \theta^T\mathbf{x}\) 实际上是用输入的线性组合\(\theta^T\mathbf{x}\)来预测对数几率 \(\log \frac{f(\theta^T\mathbf{x})}{1-f(\theta^T\mathbf{x})}\)，所以把这种方法称为对数几率回归 Logit Regression (Logistic Regression). Cost Function关于Logistic Regression的cost function，最先想到的应该是MSE，但是我们通常所见到的cost function都是由MLE的方式推出来的。一个不用MSE的原因是：当\(\theta^T\mathbf{x}\)接近\(\frac{1}{2}\)时，\(y_i - f(\theta^T\mathbf{x_i}) \)的差值会很大，使得用MSE得到的cost function对actual loss(error rate)的近似效果比较差。(More). 那么不用MSE的话，怎么来定cost function呢？ 可以发现\(f(\theta^T\mathbf{x})\)的取值在\(0 \sim 1\), 我们可以令$$f(\theta^T\mathbf{x}) = p(y = 1|\mathbf{x} )\\ 1-f(\theta^T\mathbf{x}) = p(y = 0|\mathbf{x})$$这里\(y \in \{0,1\}\), 则可以得到 $$p(y|\mathbf{x}) = f(\theta^T\mathbf{x})^{y}(1-f(\theta^T\mathbf{x}))^{1-y}$$ 相应的 Likelihood 为：$$ L = \prod_{i = 1}^{N} p(y_i|\mathbf{x_i})$$ 通过取负对数并展开，得到cost function为：$$E_{in} = - \frac{1}{N}\sum_{i = 1}^{N} y_i \log f(\theta^T\mathbf{x_i}) + (1 - y_i)\log (1-f(\theta^T\mathbf{x_i}))$$ 这里对参数\(\theta\) 的学习，我们可以使用梯度下降法来得到：$$\nabla E_{in} = -\frac{1}{N} \sum_{i=1}^{N}(y_i - f(\theta^T\mathbf{x_i}))\mathbf{x_i} \\ \theta := \theta - \alpha \nabla E_{in}$$ 正则化：为了防止过拟合，通常的做法是在优化目标中加入惩罚项，通过惩罚过大的参数来防止过拟合。常用的正则化有：L1范数和L2范数。L1正则化倾向于使参数变为0，所以可以得到更稀疏的解。 增加L1范数的优化目标： $$E_{in} = - \frac{1}{N}\sum_{i = 1}^{N} y_i \log f(\theta^T\mathbf{x_i}) + (1 - y_i)\log (1-f(\theta^T\mathbf{x_i})) ＋ \lambda ||\theta||_1$$ 需要注意的是\(||\theta||_1\)不是在所有点处都是可导的，所以这里用不了通常的gradient descent方法，这里可以用Proximal Gradient Descent (PGD) 方法来求解。 关于PGD的方法暂时不在这里介绍，会在后面关于sparse的文章里面进行介绍。 多分类：当y不是在 \(\{0,1\}\)中取值，而是可能从K个类别中取值时，我们就得到了多(K)分类问题。对于多分类任务，我们可以通过“拆解法”来解决，即将多分类任务拆分为若干个二分类任务来解决。常用的拆分策略有：一对一(OvO), 一对其余(OvR), 多对多(MvM).(更多有关“拆解法”可以参考周志华老师新书第三章)。 关于多分类任务，更常见的是用 softmax regression来解决。Softmax regression 可以看作是logistic regression在多分类任务上的推广。关于具体怎么推广的，这里不再介绍，有兴趣的读者可以通过 K-1 个\(\ln\frac{p(y = i)}{p(y = K)} = \theta_i^T\mathbf{x}\)等式来推倒(i = 1,2,…K-1)。 Softmax regression用softmax函数来对概率进行建模，具体形式如下：$$p(y = i|\mathbf{x},\theta) = \frac{e^{\theta_i^T\mathbf{x}}}{\sum_{j = 1}^{K} e^{\theta_j^T\mathbf{x}}}$$ 相应的有：$$ p(y|\mathbf{x},\theta) = \prod_{i = 1}^{K} p(y = i|\mathbf{x},\theta)^{\mathbb{1}(y = i)} $$ 对应的Likelihood：$$L = \prod_{j = 1}^{N} \prod_{i = 1}^{K} p(y_j = i|\mathbf{x_j},\theta)^{\mathbb{1}(y_j = i)} $$ 对应的cost function为：$$E_{in} = -\frac{1}{N} \sum_{j = 1}^{N}\sum_{i = 1}^{K} \mathbb{1}(y_j = i) \ln \frac{e^{\theta_i^T\mathbf{x_j}}}{\sum_{l = 1}^{K} e^{\theta_l^T\mathbf{x_j}}} $$ 这里对参数θ 的学习，我们可以使用梯度下降法来得到：$$\frac{\partial E_{in} }{\partial \theta_i} = -\frac{1}{N} \sum_{j =1}^{N} \mathbf{x_j}(\mathbb{1}(y_j = i) - \frac{e^{\theta_i^T\mathbf{x_j}}}{\sum_{j = 1}^{K} e^{\theta_j^T\mathbf{x_j}}}) $$ 关于对 softmax函数求导：$$\frac{\partial f(x_i)}{x_i} = f(x_i)(1-f(x_i)) \\ \frac{\partial f(x_i)}{x_j} = -f(x_i)f(x_j) $$ 其中，\(f(x_i) = \frac{e^{x_i}}{\sum_{i = 1}^{K}e^{x_i}}\). 由于softmax regression中参数是冗余的，这样就会使得有多组参数满足最优条件。在实际操作中，通常在优化目标基础上加上weight decay(对参数的L2正则化)来解决这一问题。 当K个类别是互斥的，适合使用softmax regression来做多分类任务；当K个类别不是互斥的，即一个\(\mathbf{x}\)可以属于多个类别，这个时候适合使用K次OvR logistic regression来做分类。 一个简单的 Logistic Regression 例子：用minfunc优化包来解决： 1234567891011121314151617clc;clear;D = [0 0 0; 2 2 0;2 0 1; 3 0 1];X = [ones(size(D,1),1) D(:,1:2)];y = D(:,3);w = zeros(3,1);gNorm = Inf;k = 1;%% using minFunc :addpath minFunc_2012/minFunc/options = struct;options.maxIter = 400;options.Method = 'lbfgs';options.useMex = 0;minFuncOptions.display = 'on';[paraTheta, cost] = minFunc(@(w) logisticCost(w,X,y),w,options); 123456789function [cost gradient] = logisticCost(w,X,y)m = size(y,1);cost = 0;for i =1:m cost = cost - (y(i)*log(sigmoid(X(i,:),w)) + (1- y(i))*log(1- sigmoid(X(i,:),w))) ;endcost = cost / m;gradient = X'*(sigmoid(X,w)-y);end 用Gradient Descent来解决： 123456789%% gradient descentg_GD = zeros(100,1);while(gNorm &gt; 1e-5) g = X'*(sigmoid(X,w)-y);w = w - g;gNorm = norm(g,2);g_GD(k) = gNorm;k = k + 1;end 用牛顿法解决： 123456789101112while(gNorm &gt; 1e-5) g = X'*(sigmoid(X,w)-y);S = diag(sigmoid(X,w).*(1-sigmoid(X,w)));H = X'*S*X;w = w - inv(H)*g;gNorm = norm(g,2);g_NT(k) = gNorm;k = k + 1;endwrongCnt = prediction(w,X,y);plot(log(g_NT)); 用拟牛顿法解决： 1234567891011121314151617181920%% BFGS method:g = X'*(sigmoid(X,w)-y);B = eye(3,3);I = eye(3,3);while norm(g) &gt; 1e-5 s = -B * g; w = w + s; g_new = X'*(sigmoid(X,w)-y); z = g_new - g; g = g_new; B = (I - s * z' ./ (z' * s)) * B * ... (I - z * s' ./ (z' * s)) + s * s' ./ (z' * s); g_BFGS(k) = norm(g); k = k + 1;endwrongCnt = prediction(w,X,y);plot(log(g_BFGS)); 123function y = sigmoid(X,w)y = 1 ./ (1 + exp(-X*w)); end 12345function [wcnt] = prediction(w,X,y)y1 = sigmoid(X,w);yNew = y1 &gt; 0.5;wcnt = sum(yNew ~= y);end Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop Notes of machine learning by Andrew Ng in cousera 机器学习 周志华 Slides by Prof. Wang 统计学习方法 Learning with sparsity-inducing norms Proximal gradient method softmax ufldl]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Logistic Regression</category>
        <category>Softmax</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Logistic Regression</tag>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linear Models for Regression]]></title>
    <url>%2F2016%2F04%2F12%2FML4%2F</url>
    <content type="text"><![CDATA[线性模型：模型输出对模型参数成线性。线性模型可以看作是一组输入变量非线性映射的线性组合。线性模型比较简单，通常在介绍一些较复杂的模型之前，先介绍线性模型作为基础；线性模型也常用作解释机器学习中一些现象的例子 (e.g., curse of dimensionality)。 令 \( D = \{(\mathbf{x_1},y_1),(\mathbf{x_2},y_2)…,(\mathbf{x_m},y_m)\}\) 为数据集，其中 \(\mathbf{x} = [x_1;x_2;…;x_n]\) 为n维列向量。当 \(y_i\) 为连续变量时，通过输入 \(\mathbf{x_i}\) 预测 \(y_i\) 为回归(regression)问题; 当 \(y_i\) 为离散变量时，通过输入 \(\mathbf{x_i}\) 预测 \(y_i\) 为分类 (classification) 问题。 Linear Regression线性回归(linear regression) 试图学到：$$ f(\mathbf{x}) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + … + \theta_n x_n$$用矩阵的形式表示为：$$f(\mathbf{x}) = \mathbf{x}^T \mathbf{\theta} $$其中，\(\mathbf{\theta} = [\theta_0;\theta_1;\theta_2;…;\theta_n]\); \(\mathbf{x} = [1,\mathbf{x}^T]\); \(f(\mathbf{x})\)为\(\mathbf{x}\)的预测值。 线性回归的cost function为均方误差MSE：$$J(\theta) = \frac{1}{2} (\mathbf{X} \mathbf{\theta} - \mathbf{y})^T( \mathbf{X} \mathbf{\theta} - \mathbf{y}) = \frac{1}{2}||\mathbf{X} \mathbf{\theta} - \mathbf{y}||_2^2$$其中，\(\mathbf{X} = [\mathbf{x_1}; \mathbf{x_2};… \mathbf{x_m}]\), \(\mathbf{x_i} 为加入1之后的向量\)。 我们将基于均方误差最小化来求解模型的方法称为“最小二乘法” (least square method). 线性回归的cost function为凸函数，我们可以直接对其求导来得到最优的\(\theta\)。$$ \frac{\partial J(\theta)}{\partial \theta} = \mathbf{X}^T(\mathbf{X}\theta - \mathbf{y})$$从而得到 \(\theta^* = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}\), 其中 \((\mathbf{X}^T\mathbf{X})^{-1}\) 为矩阵\(\mathbf{X}^T\mathbf{X}\)的逆矩阵。 然而，当数据\(\mathbf{x}\) 的维度很高时，\((\mathbf{X}^T\mathbf{X})^{-1}\) 求解需要很长时间。更常用的方法是梯度下降法 (gradient descent). Gradient Descent函数值沿着负梯度方向下降最快，梯度下降法就是基于这一点的： $$\theta := \theta - \alpha \nabla J(\theta)$$ 其中\(\alpha\)为学习率(learning rate)，用来控制每一步沿着负梯度方向走的步伐的大小。\(\alpha\)既不可太大，也不可太小。当\(\alpha\)太小时，要迭代很多次，运行时间过长；当\(\alpha\)太大时，可能会发生震荡，找不到(局部)最优值。梯度下降法是常用的一阶优化方法，但是需要对学习率进行调参。 根据计算梯度时所用的数据数量，gradient descent有三种变化： Batch Gradient Descent: $$\theta := \theta - \alpha \nabla J(\theta)$$ Batch gradient descent使用全部数据计算梯度, 所以更新一次参数\(\theta\)需要很长的时间。并且，batch gradient descent不能进行online learning。Batch gradient descent 能够保证收敛到全局最小值(目标函数为凸函数)或者局部最小值(目标函数为非凸函数)。 Stachastic Gradient Descent (SGD):$$\theta := \theta - \alpha \nabla J(\theta;\mathbf{x}_i,y_i)$$Stachastic gradient descent 每次使用一个数据去更新参数，使得参数更新很快，并且SGD可用作online learning。由于SGD更新的太过频繁，引入了过高的variance，使得目标函数\(J(\theta)\)波动较大 (见图)。 Mini-batch Gradient Descent: $$\theta := \theta - \alpha \nabla J(\theta;\mathbf{x}_{i:i+n},y_{i+n})$$Mini-batch gradient descent 使用n个数据更新参数，减小了SGD更新参数时的variance，达到更稳定的收敛。Mini-batch gradient descent是训练神经网络的一个最常用选择。 关于更多的gradient descent optimization algorithm (momenterm,Adagrad…) 暂时不在这篇博客里写了，感兴趣的可以先看下这一篇 An overview of gradient descent optimization algorithms . Newton Method当目标函数二阶连续可微时，可以使用牛顿法。牛顿法的迭代次数远小于梯度下降法。 在高数中，牛顿法是求解方程的一种近似迭代解法。例如在求解方程 \(f(x) = 0\) 时，当用求根公式求不出的时候，可以用牛顿法。对 \(f(x)\) 在 \(x_0\) 处泰勒展开得到： \(f(x) = f(x_0) + (x - x_0) \nabla f(x_0)\), 进而有 \(x = x_0 - \frac{f(x_0)}{\nabla f(x_0)}\)。 我们可以根据 \(x = x_0 - \frac{f(x_0)}{\nabla f(x_0)}\) 进行迭代来求出方程的解。 在优化问题中，我们想知道的是方程 \(\nabla f(x) = 0\) 的解。当函数二阶连续可微时，我们可以得到方程 \(\nabla f(x) = 0\) 的迭代公式： \(x = x_0 - \frac{\nabla f(x_0)}{\nabla^2 f(x_0)}\)。应用在线性回归问题上即为：$$ \theta := \theta - \frac{\nabla J(\theta)}{\nabla^2 J(\theta)} := \theta - H(J(\theta))^{-1}\nabla J(\theta)$$ 其中，\(H(J(\theta))^{-1}\)为海森矩阵的逆矩阵，计算复杂度相当高，在高维问题中几乎不可行。拟牛顿法用较低的计算代价来寻找海森矩阵逆矩阵的近似矩阵，从而可显著性的降低计算开销。比较常用的拟牛顿法是l-bfgs算法。minFunc 是机器学习中一个常用的matlab优化包, 只需要自己实现cost和梯度，用minFunc实现线性回归的代码如下： 12345678910111213141516addpath minFunc_2012/minFunc/x = 1:1:12;x = x';y = [0.74 1.41 1.45 1.49 1.21 1.31 1.68 2.04 1.58 1.23 1.50 1.67 ]*0.01;y = y';%% using minFunc :options = struct;options.maxIter = 400;options.Method = 'lbfgs';options.useMex = 0;minFuncOptions.display = 'on';theta0 = [0; 0];X = [ones(size(x)) x];[paraTheta, cost] = minFunc(@(p) linear_regression(p,X,y),theta0,options);yNew = X*paraTheta; 1234function [cost, gradient] = linear_regression(theta,X,y) cost = 0.5*norm(X*theta-y,2); gradient = X'*(X*theta - y);end Linear Basis Function Models对于一般的线性模型有：$$ f(\mathbf{x}) = \theta_0 + \sum_{j = 1}^{M-1} \theta_j \phi_j(\mathbf{x}) = \phi(\mathbf{x})\theta $$ 其中，\(\phi(\mathbf{x})\) 为基函数，常用的基函数有：多项式函数、高斯函数、sigmoid函数。相应的cost function为： $$J(\theta) = \frac{1}{2} ||\Phi \theta - \mathbf{y}||_2^2$$ 相应的最优解 \(\theta^{*} = (\Phi^T \Phi)^{-1} \Phi^T \mathbf{y}\). Ridge Regression以多项式回归为例，当模型变得更复杂 (所用的\(x^{j}\)阶数越高)时，会出现overfitting的情况，可以发现此时相应的参数\(\theta_i\)会非常大。通常用来控制这种overfitting的做法是，对参数加一个限制：\(\theta^T\theta \leq C\). 这样就得到了如下的 ridge regression: $$ \min_{\theta} \ J(\theta) = \frac{1}{2} ||\Phi \theta - \mathbf{y}||_2^2 \\ s.t. \ \theta^T\theta \leq C$$. 上式等价于：$$ \min_{\theta} \ J(\theta) = \frac{1}{2} ||\Phi \theta - \mathbf{y}||_2^2 ＋\frac{\lambda}{2} \theta^T\theta $$. Ridge regression 是一个典型的凸优化问题，可以通过凸优化包来解决。 Lasso当我们用1-范数对参数\(\theta\)进行约束时，就得到了LASSO： $$ \min_{\theta} \ J(\theta) = \frac{1}{2} ||\Phi \theta - \mathbf{y}||_2^2 \\ s.t. \ ||\theta||_1 \leq C$$. 上式等价于：$$ \min_{\theta} \ J(\theta) = \frac{1}{2} ||\Phi \theta - \mathbf{y}||_2^2 ＋\lambda ||\theta||_1 $$. Optimality Condition for LASSO:对 \(J(\theta) = \frac{1}{2} ||\Phi \theta - \mathbf{y}||_2^2 ＋\lambda ||\theta||_1 \) 求导时，我们发现第一项是可导的，但是第二项在\(\theta_i\)为0时，不可导。这里需要引入次微分和次梯度来解决。次微分和次梯度是对导数的一个推广(不可导的情况)，通常用在凸优化中。 对一个凸函数\(f\)有 \(f(y) \geq f(x) + \nabla f(x)^T(y-x)\), 则 \(g\) is a subgradient of a convex function \(f\) at \(x \in D(f)\) if :$$ f(y) \geq f(x) + g^T (y-x)$$ 次微分(subderivative)是所有满足 \(f(y) \geq f(x) + g^T (y-x)\) 的\(g\) 形成的集合\(\partial f(x)\)。对于非光滑凸函数，一阶最优性条件为：\(0 \in \partial f(x)\) 或者 \(\exists g \in \partial f(x), \ s.t. \ g = 0\)。(即对于光滑可导函数，我们将导数为零作为一阶最优条件；对于非光滑凸函数，我们将0是否在次微分集合作为一阶最优条件)。 回到LASSO这个问题上，我们可以得到其一阶最优化条件：$$0 \in \Phi^T(\Phi\mathbf{X} - \mathbf{y}) + \lambda \partial ||\theta||_1$$ Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop Notes of machine learning by Andrew Ng in cousera 机器学习 周志华 Slides by Prof. Wang Sebastian Ruder’s blog - An overview of gradient descent optimization algorithms 统计学习方法 subderative subgradients by Stephen Boyd]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Linear Regression</tag>
        <tag>Gradient Descent</tag>
        <tag>Newton Method</tag>
        <tag>Ridge Regression</tag>
        <tag>Lasso</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Model Selection and Evaluation]]></title>
    <url>%2F2016%2F04%2F07%2FML3%2F</url>
    <content type="text"><![CDATA[前面两篇分别写了机器学习的简介和一些必备的基础知识，这一篇打算写下模型评估和选择。 经验误差和过拟合我们把学习器实际预测输出和样本真实输出之间的差异称为误差。学习器在训练集上的误差称为经验误差；在新样本上的误差称为泛化误差。显然，我们希望得到泛化误差小的学习器。然而，在现实中，我们并不知道新的样本什么样，能做的只是去最小化经验误差。 我们希望得到泛化能力强的学习器，即希望学习器在训练样本中学到适合所有潜在样本的“普遍规律”。然而，学习器学习能力过强时，会将训练样本自身拥有的一些特点当作是适合所有潜在样本的规律，这样在新样本上的泛化误差必然会变大。这种现象叫做过拟合。与过拟合相对的是欠拟合，欠拟合一般是由于学习器学习能力太弱导致的。造成过拟合的因素有很多，比较常见的是学习器学习能力过强，而样本相对太少；这样学习器就会学到训练样本中不太一般的特性。过拟合往往是不可避免的，但是可以缓解。暂时打算在后面维度诅咒的博客里，举一些过拟合的例子。 评估方法在现实任务中，对于同一个问题，我们可以选择很多种学习算法；甚至对于同一个学习算法，当选择参数不同的时候，就会产生不同的模型。我们该选择哪一种学习算法，哪一种参数配置呢？这时就要用到模型选择了 (Model Selection). 通常我们拿到一个新的数据集，先将数据集 \(D\) 的30%(不超过\(\frac{1}{3}\))用作测试集(test set)，然后再用剩下的数据\(D_{1}\) 来训练和选择模型(即用做训练集(training set)和验证集(validation set)). 对于训练集和验证集的划分，在不同情况下，有不同的适合划分的方法。 留出法留出法直接将 \(D_{1}\) 划分为两个互斥的集合，其中一个集合作为训练集，一个作为验证集。需要注意的是，划分数据集时应尽量保持数据的分布一致性。不然会因为划分数据的过程引入额外的误差从而对最终结果产生影响。比如二分类问题，\(D_{1}\) 有1000个样本，其中正例500个，负例500个。我们现在选70%作为训练集，30%作为验证集。为了保持样本数据分布一致性，我们从正例中取70%负例中取70%作为训练数据。正例和负例中剩下的部分作为验证集。如果从采样角度来看数据划分的话，保留类别比例的采样方式通常称为分层采样。 留出法需要对数据集\(D_{1}\)进行划分，这就会导致一种窘境：如果训练集S包括绝大多数样本，则训练出的模型可能更接近用\(D_{1}\)训练出的模型，但由于验证集V样本数量过少，评估结果可能不够稳定准确。如果验证集V多包括一些样本，则用训练集S训练出的模型和用\(D_{1}\)训练出的模型可能有较大的差别。这个问题没有十分完美的解决方案，常见的做法就是用大约\(\frac{2}{3} \sim \frac{4}{5}\)样本作为训练集，其他用做验证集。留出法的好处在于简单，而且只需要训练一次模型；缺点在于上面提到的窘境。 交叉验证法 (Cross Validation)交叉验证法先将数据集\(D_{1}\)划分为k个互斥的子集，并且每个子集尽可能保持数据分布的一致性(从\(D_{1}\)中分层采样)。然后每次用k－1个子集作为训练集，用剩下的作为验证集。这样我们就得到了K组训练集/测试集。最终我们把k个验证集评估结果的平均值来作为该模型的评估值。交叉验证的稳定性和保真性(fidelity)很大程度上取决于k的取值。为了突出这一点，通常又称为k折交叉验证(k-fold cross validation)。 k最常用的取值是10. 当k等于\(D_{1}\)样本个数m的时候，就得到交叉验证的一个特例：留一法 (LOOCV). 留一法每次只有一个样本作为验证集，这样就免除了随机划分样本方式的影响。同时，留一法每次用m－1个样本来训练数据，使得训练出的模型和在\(D_{1}\)上训练出的模型很相似。但是，留一法每次要跑m次模型学习和预测的算法，当m比较大或者模型的复杂度比较高时，运行时间是很长的。通常留一法用在训练数据比较少的情况。 性能度量 (Evaluation)：性能度量是衡量模型泛化能力的评价标准。 在对比不同模型的能力时，选择不同的性能度量，往往会导致不同的评判结果。 均方误差 (Mean Square Error):回归问题常用的性能度量是均方误差(MSE):$$E(f,D) = \frac{1}{m} \sum_{i = i}^{m} (f(\mathbf{x_i}) - y_i)^2$$ 其中，\(D = \{(\mathbf{x_1},y_1),(\mathbf{x_2},y_2),…(\mathbf{x_m},y_m)\}\) 为训练集，\(y_i\)为样例\(\mathbf{x_i}\)的label。\(f\) 为我们学到的模型(预测函数)。 均方误差评估的是学习器 \(f\) 的预测结果和真实结果差异。 下面介绍分类任务中常用的性能度量。 错误率与精度：错误率和精度是分类任务中经常用到的性能度量标准，即可用在二分类任务上，也可用在多分类任务上。错误率是分类错误的样本占总样本数的比例，精度是分类正确的样本占样本数的比例，错误率＝ 1 - 精度。用公式表示就是：$$E(f;D) = \sum_{i=1}^{m} \mathbb{1}(f(x_i) \neq y_i)$$$$acc(f;D) = \sum_{i=1}^{m} \mathbb{1}(f(x_i) = y_i)$$ 准确率 (Precision)、召回率 (Recall) 与 F1：错误率和精度虽然很常用，但是并不能满足所有的任务需求。比如在信息检索，web搜索应用中，我们想知道“检索出的信息中有多少比例是用户感兴趣的”(准确率)，或者“在用户感兴趣的信息中，有多少被检索出来”(召回率)。 下面以一个例子说明，precision 和 recall 的具体计算公式。对应检索信息和用户兴趣这个例子，有如下混淆矩阵： 用户感兴趣(真实情况) 用户不感兴趣(真实情况) 被检索出(预测结果) True Positive (TP) False Positive (FP) 未被检索出(预测结果) False Negative (FN) True Negative (TN) 其中，TP＋FP＋FN + TN = 样本总数。 则准确率：$$ P = \frac{TP}{TP+FP}$$ 召回率：$$ R = \frac{TP}{TP + FN}$$ 通常来讲，准确率和召回率是一对矛盾的度量。一般来说，准确率高时，召回率低；召回率高时，准确率偏低。比如一共有m个样本，其中p个正样例，n个负样例。取极限情况，当只检测出一个样本，且它是正样例，则准确率为100%，而召回率为\(\frac{1}{p}\). 当全部样本都被检测出来，召回率为100%, 而准确率为\(\frac{p}{m}\). 以准确率为纵轴，召回率为横轴，绘制的P-R曲线，常被用作衡量模型优劣的一个标准。如果P-R曲线中，一个曲线\(l_1\)完全包住另一个曲线，则认为\(l_1\)对应的学习器效果好。“平衡点” (Break-Even Point 简称：BEP)为P-R曲线上召回率＝准确率处的点。若模型的BEP点高，说明该模型的准确率和召回率取得相对“双高”的比例，则该模型的效果较好。 但是BEP还是过于简化了些，更常用的是F1度量：$$F1 = \frac{2\times P \times R}{P + R} = \frac{2\times TP}{m-TN + TP}$$ F1 是基于准确率和召回率的调和平均 (harmonic mean) 来定义的.$$\frac{1}{F_1} = \frac{1}{2}(\frac{1}{P} + \frac{1}{R})$$. 然而在一些应用中，对准确率和召回率的重视程度是不同的。例如在商品推荐系统中，为了尽可能少的打扰客户，更希望推荐的内容是客户感兴趣的，这时准确率更重要；在逃犯信息检索系统中，更希望尽可能少的漏掉逃犯，此时召回率更重要。F1的一般形式\(F_{\beta}\)，能让我们表达出对准确率和召回率的不同偏好。$$ F_{\beta} = \frac{(1+ \beta^2)\times P \times R}{(\beta^2 \times P) + R}$$\(\beta = 1\) 时，\(F_{\beta}\) 变为\(F1\); \(\beta &lt; 1\) 时，准确率有更大影响；\(\beta &gt; 1\) 时， 召回率有更大影响。 当我们有n个混淆矩阵的时候(多分类任务，或者进行多次训练／测试等)，我们如何来求准确率和召回率呢？一种直接的做法是在每个混淆矩阵上分别求出准确率和召回率，然后将这n个准确率和召回率的平均值来作为这n个矩阵的准确率\(\bar P\)、召回率\(\bar R\)，然后用\(\bar P\)和\(\bar R\)算出相应的F1。另一种做法是对n个混淆矩阵的对应元素取平均值，得到\(\bar {TP} \ \bar {FP} \ \bar {TN} \ \bar {FN} \), 在基于这些平均值来计算准确率、召回率和F1. \(R^2\) (Coefficient of Determination)这学期在上王浩老师的机器学习课程，在课上他提到，现在业界很多都通过\(R^2\)来看学习器性能好坏。\(R^2\)衡量的是数据有多大程度上fit我们的model。$$R^2 = 1 - \frac{\sum_{i=1}^{m} (f(\mathbf{x_i}) - y_{i})^2}{\sum_{j=1}^{m} (y_{j} - \bar y)^2} = 1- \frac{SS_{res}}{SS_{tot}}$$. \(R^2\)多用于回归问题上，当\(R^2\)越接近1时，说明我们的regression line越完美的fit数据；当\(R^2\)越接近0时，说明regression line 越不fit数据。 非均等代价在现实生活中经常会遇到这种情况，不同类型的错误会造成不同的后果。比如将一个患者诊断为健康人和将一个健康人诊断为患者。后者的影响是增加了进一步检查的麻烦，而前者的后果却可能是失去了拯救生命的最佳时机。为了权衡不同类型错误所造成的不同损失，可以使用非均等代价。 在前面的性能度量中，都隐性的假设了均等代价。而在非均等代价中，我们希望最小化的是“总体代价”。更详细的描述可以参考周志华老师机器学习新书. 比较检验：当我们在测试集上得到了学习器的某个性能度量的结果，我们可以用这个数值通过比大小的方式来比较不同学习器的泛化能能力吗？在机器学习中，比较这件事比通常想象的要复杂。对于学习器泛化能力的比较，我们要用统计假设检验来说明若在测试集上观察学习器A比学习器B要好，则在统计意义上A的泛化性能是否优于B。更多详细描述可以参考周志华老师新书. Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop notes of machine learning by Andrew Ng in cousera GPCA (Generalized Principle Component Analysis) by Yi Ma (to be published) 机器学习 周志华]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Model Selection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Statics and Optimization in Machine Learning]]></title>
    <url>%2F2016%2F03%2F31%2FML2%2F</url>
    <content type="text"><![CDATA[Machine Learning 是一门集计算机、统计和优化于一体的学科。这一篇打算写一些机器学习中常用到的统计和优化的基础知识。由于时间有限，英文和中文哪个方便就用哪个写了^_^。 Jenson’s Inequality:Jenson 不等式是机器学习中经常用到的一个不等式。有时我们在evaluate一个变量函数的期望的时候，可能我们不需要知道这个期望的确切数值，只需要知道这个期望的bound就足够了。这时我们就可以用到Jenson不等式。Jenson不等式在推倒EM算法公式的时候会被经常用到。 令 \(X\)为一随机变量，\(f\)为关于\(X\)的凸函数，则有： $$ E(f(X)) \geq f(E(X))$$ 如果 \(f\)为凹函数，则有， $$E(f(X)) \leq f(E(X))$$ SVD 分解: SVD分解是机器学习中常用到的一种矩阵分解方法。SVD是PCA算法的主要实现手段，而PCA算法又是机器学习中用的最多的降维的方法。 矩阵 \(X\) 的 SVD 分解为 \(X ＝ U_X \Sigma_X V_X^T\)，其中 \(X=[x_1,x_2,…x_N] \in R^{D\ \times N}\)，\(U_X \in R^{D\ \times D}\), \(\Sigma_X \in R^{D\ \times N}\), \(V_X \in R^{N\ \times N}\). 其中，\(U_X\), \(V_X\)为unitary matrix (\(U U^{* } = U^{\ * } U = I \))，\(\Sigma_X\)为奇异值矩阵。 PCA via SVD: 令 \(X=[x_1,x_2,…x_N] \in R^{D \times N}\)为减去均值后的数据集，\(X\)的SVD分解结果为 \(X ＝ U_X \Sigma_X V_X^T\), 则经过降维后的数据集为\(\Sigma_X V_X^T\)的顶部\(d\times N\)部分；降维转换矩阵\(U\)为\(U_X\)的前d列。 ps:关于PCA的推倒和实现会在后续文章里提到。暂时打算将降维和维度诅咒写在一起。 Matrix Calculus: 梯度下降法是机器学习中用的最多的算法之一，而它的关键就是对矩阵求导。求导在 deep learning 里面也是关键。然而矩阵求导一直是我的弱项，复杂一点的有时候要求好久，下面好好梳理下矩阵求导。 若 \(\mathbf{x}\) 为 \(n\) 维向量，\(f：R^{n} \rightarrow R^{m} \) 为关于 \(\mathbf{x}\) 的函数，则 \((\frac{\partial f}{\partial \mathbf{x}})_{ij} = \frac{\partial f_i }{\partial x_j}\). 若 \(\mathbf{x}\) 为 \(n\) 维列向量，\(f：R^{n} \rightarrow R \) 为关于 \(\mathbf{x}\) 的函数，则 \(\frac{\partial f}{\partial \mathbf{x}}\) 为\(n\) 维行向量，且\(\frac{\partial f}{\partial \mathbf{x}} = [\frac{\partial f}{\partial x_{i}}]\). 若 \(\mathbf{X}\) 为 \(m \times n\) 的矩阵， \(f：R^{m\ \times n} \rightarrow R \) 为关于 \(\mathbf{X}\) 的函数，则 \(\frac{\partial f}{\partial \mathbf{X}}\) 为\(n \times m\) 的矩阵，且\([\frac{\partial{f}}{\partial \mathbf{X}}]_{ij} = [\frac{\partial f}{X_{ji}}]\). 矩阵求导的三步： 1 弄清求导的维度 2 根据求导的维度，将 \(f\) 展开成关于 \(x_i\) 的形式，然后用element-wise calculations 算出每一项的导数 3 将算出来的每一项导数放到向量或者矩阵里面。 Example 1: scalar by vector \( \frac{\partial (\mathbf{x}^{T}\mathbf{a})}{\partial \mathbf{x}} = \frac{\partial (\mathbf{a}^{T} \mathbf{x})}{\partial \mathbf{x}} = \mathbf{a^{T}}\) . 根据矩阵求导三步：1. \(\mathbf{x}^{T}\mathbf{a}\) 是两个向量的内机，为scalar；\( \mathbf{x}\)是向量，所以 \(\frac{\partial f}{\partial \mathbf{x}} = [\frac{\partial f}{\partial x_{i}}]\) 是一个行向量. 2. \(\mathbf{x}^{T} \mathbf{a} ＝ \sum_{i=1}^{n} a_i x_i\), 所以 \(\frac{\partial f}{\partial x_{i}} = a_i\). 3. 将每一项求导结果放在向量中就得到了结果：\( \mathbf{a^{T}}\). Example 2: \( q(x) = || Ax - b||_2^2\), where \(A\) is \(m \times n\), \(x\) is \(n \times 1\), \(b\) is \(m \times 1\), \(\frac{\partial q(x)}{x} = ?\) 首先看几个其他公式： \(y = Ax\), \(\frac{\partial y}{\partial x} = A\), \(\frac{\partial y}{\partial z} = A \frac{\partial x}{\partial z}\) \(\alpha = y^T Ax\), \(\frac{\partial \alpha}{\partial x} = y^T A\); \(\alpha = x^T A^T y\),\(\frac{\partial \alpha}{\partial y} = x^T A^T\); \( \frac{\partial \alpha}{\partial A} = yx^{T}\); \(\alpha = y^T x\), \(\frac{\partial \alpha}{\partial z} = x^T \frac{\partial y}{\partial z} + y^T \frac{\partial x}{\partial z}\); Proof: \(\frac{\partial \alpha}{\partial z} = \frac{\partial \alpha}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial \alpha }{\partial x}\frac{\partial x}{\partial z} = x^T \frac{\partial y}{\partial z} + y^T \frac{\partial x}{\partial z} \) \(\alpha = x^Tx\),\(\frac{\partial \alpha}{\partial x} = 2x^T\); \(\alpha = x^TAx\), \(\frac{\partial \alpha}{\partial x} = (Ax)^T + x^TA = x^T(A^T + A)\) 回到我们这个问题上，\( q(x) = || Ax - b||_2^2 ＝ (Ax-b)^T (Ax-b)\), 则从上面公式可得：\(\frac{\partial q(x)}{\partial x} = 2(Ax-b)^T \frac{\partial (Ax-b)}{\partial x} = 2(Ax-b)^TA\). \(f(x)\) 关于\(x\) 的二阶导数称为Hessian matrix：\([\frac{\partial^2f(x)}{\partial x^2}]_{ij} = \frac{\partial^2f(x)}{\partial x_i \partial x_j}\), 其中，\(\mathbf{x}\) 为 \(n\) 维列向量，\(f：R^{n} \rightarrow R \) 为关于 \(\mathbf{x}\) 的函数。 ps：更多关于矩阵求导相关公式会在深度学习中提到。 Optimization: 刚看了周志华老师新书的附录部分，发现我想写的里面都有，而且深入浅出，浅显易懂^_^。关于优化部分，主要想写下拉格朗日乘子法、KKT条件和一些其他的凸优化相关知识。 拉格朗日乘子法： 拉格朗日乘子法是寻找多元函数在一组约束条件下极值的方法；通过引入拉格朗日乘子，将d个变量在k个约束条件下的极值问题转化成d＋k个变量无约束的极值问题。PRML这本书的附录E里面有更加详细的关于拉格朗日乘子的介绍。 等式约束： 假设 \(\mathbf{x}\) 为 d 维向量，我们要找到一个取值\(\mathbf{x^{*}}\), 使得目标函数 \(f(\mathbf{x})\) 在约束条件\(g(\mathbf{x})=0\) 下取得最小值。 满足约束条件\(g(\mathbf{x})=0\) 的点在一个 \(d-1\) 维的曲面上，对于约束曲面上的任意一点\(x_i\)，它的梯度 \(\nabla g(\mathbf{x_i})\) 都正交于该曲面。对于我们要找的 \(\mathbf{x^{*}}\), 目标函数在该点的梯度 \(\nabla f(\mathbf{x^*})\) 也要正交于约束曲面。因为如果不正交的话，我们可沿着梯度方向在约束曲面上移动一小段距离，从而可以找到更小的值。也就是\(\nabla g(\mathbf{x}) + \lambda \nabla f(\mathbf{x}) = 0\), 其中，\(\lambda \neq 0\)。 下面引出拉格朗日函数：\(L(\mathbf{x},\lambda) = f(\mathbf{x}) + \lambda g(\mathbf{x})\). 将 \(L(\mathbf{x},\lambda)\) 对 \(\mathbf{x}\) 求导可得：\(\nabla f(\mathbf{x}) + \lambda \nabla g(\mathbf{x}) = 0\)； 对\(\lambda \) 求导可得：\(g(\mathbf{x})=0\). 所以对拉格朗日函数的无约束优化即等价于原等式约束优化。 不等式约束：当\(g(\mathbf{x}) \leq 0\), 有两种情况： \(g(\mathbf{x}) &lt; 0\) 时, 约束条件 \(g(\mathbf{x}) \leq 0\) 不起作用，此时等价于 \(\lambda ＝ 0\)，可直接通过 \(\nabla f(\mathbf{x}) = 0\) 求解. \(g(\mathbf{x}) = 0\) 时，情况和上一条等价约束比较类似，不过此处 \( \lambda&gt; 0\). 由此引出KKT条件： \(\nabla g(\mathbf{x}) + \lambda \nabla f(\mathbf{x}) = 0\) \(g(\mathbf{x}) \leq 0\) \( \lambda \geq 0\) \( \lambda g(\mathbf{x}) = 0 \) 综上，当有多个约束时，考虑有 m 个等式约束和 n 个不等式约束,$$\min_{\mathbf{x}} f(\mathbf{x}) \\ s.t. \ h_{i}(\mathbf{x})=0 \ (i = 1,2,…m) \\ g_{j}(\mathbf{x}) \leq 0 \ (j = 1,2,…n) $$ 引入拉格朗日乘子，\(\mathbf{\lambda} = (\lambda_{1},\lambda_{2},\ldots,\lambda_{m})^{T}\), \(\mathbf{\mu} = (\mu_{1}, \mu_{2},\ldots,\mu_{n})^{T} \), 得到拉格朗日函数为： \(L(\mathbf{x},\mathbf{\lambda},\mathbf{\mu}) = f(\mathbf{x}) + \sum_{i=1}^{m}\lambda_{i} h_{i}(\mathbf{x}) + \sum_{j=1}^{n} \mu_{j} g_{j}(\mathbf{x})\) 其中，由不等式引入的 KKT 条件为 (\(j = 1,2,\ldots,n\))： \( g_{j}(\mathbf{x}) \leq 0 \) \(\mu_j \geq 0\) \(\mu_j g_j(\mathbf{x}) = 0\) Convexity Optimization通过上面拉格朗日乘子和KKT条件算出的结果只是必要条件，只有当目标函数是凸的情况下，才能保证是充分必要条件 (取到全局最优)。通常来讲，找一个函数的全局最优解是很难的；但是如果我们可以将一个问题formulate 成凸优化问题，解决起来会容易很多。 Convex Sets在判断一个函数是不是凸函数的时候，首先要看它的定义域是不是一个凸集；所以首先介绍下什么是凸集。 Definition: A set \(C \) is convex, if for all \(x,y \ in \ C \) and \(\theta \in R\) with \(0 \leq \theta \leq 1\), \(\theta x + (1-\theta)y \in C \). 意思就是说，对于集合中任意两个元素，我们在这两个元素之间做一条线段，如果线段上的所有点都在集合内，则这个集合就是凸的。 常见的凸集有： All of \(R^{n}\) The non-negative orthant, \(R_{+}^{n}\): \(R_{+}^{n} = \{x: x_i \geq 0 \ \forall i= 1,2,…n \}\) Norm balls: e.g., \(||x|| \leq 1\) Affine subspaces \(\{x \in R^{n} : Ax = b\}\) and polyhedra \(\{x \in R^{n} : Ax \preceq b\}\), where \(\preceq \) denotes componentwise inequality. Intersections of convex sets Positive semidefine matrices \(S_{+}^{n}\): \(A = A^{T},\) and for all \(x \in R^{n}\), \(x^{T}Ax \geq 0\). Convex Functions:凸函数是凸优化中一个比较核心的概念，被用在凸优化各个方面。 Definition: A function \(R^{n} \rightarrow R \) is convex, if its domain (denoted as D(f)) is a convex set, and if for all \(x,y \in D(f)\) and \(\theta \in R \) with \(0 \leq \theta \leq 1\), \(f(\theta x + (1-\theta)y) \leq \theta f(x) + (1-\theta)f(y)\). 如果该等式左侧在该条件下(且\(x \neq y\))恒小于右侧，我们就说该函数是 strictly convex。 如果一个函数 \(f \)的负数 \(-f \) 是凸函数，则该函数 \(f\)为凹函数。 如果函数 \(f \) 是凸函数，则它的局部最小值即为它的全局最小值。如果 \(f \) 是strictly convex的，\(f \) 最多只有一个全局最小值；也就是说如果\(f \)有最小值，那么这个最小值就是唯一的。 First Order Condition of Convexity:Suppose a function \(R^{n} \rightarrow R \) is differentiable (i.e., the gradient \(\nabla f(x)\) exists for all \(x\) in the domain of \(f\)). Then \(f \) is convex, if and only if \(D(f)\) is a convex set and for all \(x, y \in D(f)\), \(f(y) \geq f(x) + \nabla f(x)^{T}(y-x)\). 也就是说我们在点\(x\)处做切线，用这个切线上的点来近似函数\(f\)上的点，那么这个切线上的所有点都在函数\(f\)相应点的下方。如果恒大于的话，即为strictly convex；如果不等号相反，那么\(f\)即为凹函数。 Second Order Condition of Convexity: Suppose a function \(R^{n} \rightarrow R \) is twice differentiable (i.e., the Hessian Matrix \(\nabla^{2} f(x)\) is defined for all \(x\) in the domain of \(f\)). Then \(f \) is convex, if and only if \(D(f)\) is a convex set and \(\nabla^{2} f(x)\) is positive semidefine. If \(\nabla^{2} f(x)\) is positive define, then \(f\) is strictly convex. If \(\nabla^{2} f(x)\) is negative semidefine, then \(f\) is concave. 当\(x\)为一维的时候，即为\(\nabla^{2} f(x) \geq 0\) If \(f\) is convex, then the \(\alpha\)-sublevel set (\(x \in D(f): f(x) \leq \alpha\)) is a convex set. 常见的凸函数 Exponential functions Negative logarithm: Affine functions: \(f(x) = b^{T}x + c\), \(b \in R^{n}, \ c \in R\). In this case \(\nabla^{2} f(x) = 0\), the affine functions of this form are the \(\mathbf{only}\) functions that are both convex and concave. Quadratic functions: \(f(x) = x^{T}Ax + b^{T}x + c \), when \(A\) is symmetric and \(A\) is positive semidefine, \(f(x)\) is convex. ( \(\nabla^{2} f(x) = A\)). Norms (using the definition to prove it) Nonnegative weighted sums of convex functions Convex Optimization Problems:$$\min_x f(x) \\ s.t. g_i(x)\leq 0, \ i= 1,2,…n \\ h_j(x) = 0,\ j = 1,2,…n $$where \(f\) is a convex function, \(g_i\) are convex functions and \(h_i\) are affine functions. Special cases of convex problems: Linear Programming (LP):$$\min_x c^{T}x + d \\ s.t. Gx \preceq h \\ Ax = b$$where \(\preceq \) denotes elementwise inequality. Quadratic Programming (QP):$$ \min_x \frac{1}{2} x^{T}Px + c^{T}x + d \\ s.t. Gx \preceq h \\ Ax = b$$ where \(P\) is a symmetric positive semidefine matrix. Quadratically Constrained Quadratic Programming (QCQP):$$\min_x \frac{1}{2} x^{T}Px + c^{T} +d \\ s.t. \frac{1}{2} x^{T}Q_ix + r_i^{T}x + s_i \leq 0 \ \ i = 1,2…,m \\ Ax= b$$where \(P\) and \(Q_i\) are symmetric positive semidefine matrices. 共轭分布、多项分布与 Dirichlet 分布在很多模型中 (e.g., LDA)，一个节点到其他节点的概率之和为1，这时我们就用多项分布来建模。比如现在我们有一个\(d\)维向量\(\mathbf{x}\), 其中\(\mathbf{x}\)是 1-of-K 的形式。令\(x_i\)取1 的概率为\(\mu_i\), 并且\(\sum_{i = 1}^{d}\mu_i = 1\),那么我们就能得到关于\(\mathbf{x}\)的多项分布：\(P(\mathbf{x}|\mathbf{\mu}) = \prod_{i=1}^{d} \mu_i^{x_i}\). 其中，\(\mathbf{\mu}\)即为我们模型的参数。 现在我们想对参数\(\mathbf{\mu}\)加先验，我们认为参数\(\mathbf{\mu}\)服从一个分布。通常来讲，我们都会选共轭分布来作为先验分布 (在很多情况下，共轭分布能使问题简化)。多项分布的共轭分布是Dirichlet 分布，因为将多项分布和Dirichlet 分布相乘仍是Dirichlet 分布。在生成模型中，多项分布和Dirichlet 分布用的比较多，这里先简单介绍下，在后面的LDA模型中，我会详细介绍。 Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop notes of machine learning by Andrew Ng in cousera GPCA (Generalized Principle Component Analysis) by Yi Ma (to be published) 机器学习 周志华 Matrix Differentiation Matrix CookBook Notes of CS229 in Stanford]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>SVD</tag>
        <tag>Jesen&#39;s Inequality</tag>
        <tag>Matrix Calculus</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction]]></title>
    <url>%2F2016%2F03%2F19%2FML1%2F</url>
    <content type="text"><![CDATA[接触machine learning已经有一年多的时间了，在这段时间里，经历了从不懂到了解，从了解到理解，从理解到运用的几个阶段。起初开始学习maching learning的时候，一般以看为主，很少自己推倒，这样过了一段时间之后，发现之前看的算法基本都忘了。后来上马毅老师GPCA课的时候，他曾告诫我们，要想把知识学好并变为自己的东西，最好的办法就是自己从头到尾推倒一遍. 在做数据科学国际大会SSDS2015志愿者的时候，有幸负责接送Eric Xing教授，在路上和他聊天的时候，Eric也指出学习maching learning一定要自己推倒，这是最基本的要求。在这之后的学习中，对所遇到的算法，都要自己推倒一番，发现效果很不错。 一直想整理machine learning方面的知识写成博客，但总是找不到太合适的时间。最近学院学分政策变了，我选了学院machine learning的课，加上最近在读周志华老师机器学习的新书，便决定把之前学习的maching learning知识好好梳理一下。 What is machine Learning?Arthur Samuel (1959): “Field of study that gives computers the ability to learn without being explicitly programmed.” Tom Michel (1999): “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” My understanding：machine learning gives the computers the ability to learn, and according to different tasks, the computers learn different things in order to improve the performance. The machine learning algorithms can solve problems better than the algorithms used in the old days. Exapmle: Recognizing handwritten digits. Recognizing handwritten digits is not a nontrival problem due to the wide variability of handwritting. It can be tackled using handcrafted rules for distinguishing the digits based on the shapes of the strokes, but in practice such an approach leads to a proliferation of rules and of excpetions to the rules and so on, and invariably gives poor performance. However, using the machine learning methods can get a much better performance. Example. In recent research, the use of deeplearning methods can reduce the error rate of recognizing handwritten digits down to less than 0.5%. Why machine learning?机器学习可以比较好的解决传统编程不能解决好的问题。就拿手写体识别这个例子来说，如果用传统编程的方式，我们很难设计手写体的全部规则并加以编程实现。但如果把这个问题用机器学习的算法来解决，实现起来比较简单，效果也好。 Inductive learning机器学习－“从样例中学习”是一个归纳过程，所以也称为归纳学习。通常我们假设整个样本空间(由特征张成的空间)服从一个未知的分布D，每个样本都是从这个分布上独立同分布的采样得到的。我们获得的样本越多，对样本空间的信息知道的就越多。训练集只是样本空间的一个很小的采样，但是我们希望它能够很好的反映样本空间的特性，否则在训练集上学到的模型范化能力会比较差。 我们可以把模型的学习过程看成是一个在由所有假设组成的空间中进行搜索的过程，搜索目标是与训练集相匹配的假设。但是在实际问题中，假设空间会很大，可能会得到很多个和训练集相匹配的假设(版本空间)。如何在版本空间中选择我们需要的模型？一种选择标准是“奥卡姆剃刀”。“奥卡姆剃刀”是一种常用的，自然科学研究中最基本的原则，即“若有多个假设与观察一致，选择最简单的那个”。但是在模型选择上，通常不好定义什么是“简单”。 另一个标准是归纳偏好(inductive bias)，即对某种类型假设的偏好。 No Free Lunch Theorem (NFL)NFL(没有免费的午餐定理)是说，无论算法a多聪明，算法b多笨拙，他们的期望性能是相同的。NFL有一个重要前提：所有问题同等重要。但有的时候我们只关心自己试图正在解决的问题，并不关心这个方案在其他问题上的效果。 NFL让我们认识到，脱离具体问题去空谈“什么学习算法好”毫无意义，因为若要考虑所有问题，所有算法都一样好。所以若要讨论算法的相对优劣，必须针对具体问题。在有些问题上表现比较好的算法，在其他问题上却可能不尽人意。 Some conceptsSupervised Learning Teach the computer how to do something, then let it use it; the data has labels example: linear regression，classification Unsupervised Learning Let the computer learn how to do something, and use this to determine structure and patterns in data the data has no labels example : clustering For more detailed examples for unsupervised and supervised learning, you can see this. Generative Models Generative Models are used to model how data are generated. For example, you are given a dataset and you plot the instances in the dataset. From the plot, you find the distribution look like Gaussian distribution. Then you choose Gaussian distribution as your model. Now, you think your dataset are genereatd from this Gaussian distribution. For each instance, there is a generating probability \(p_i\), then the likelihood of generating the whole dataset is \(\prod_{i=1}^{N}p_i\), so we can learn the parameters by maxmizing the likelihood. What if we cannot plot the dataset? In this case what kind of models should we use? Model selection can solve this problem well and it will be introduced in the following part. Another view : Generative Model: Modeling the joint distribution of all data. If the goal is to learn f: X –&gt; Y, e.g., P(Y|X), generative models estimate parameters of P(X|Y),p(Y) directly from training data. Then we can use Bayes rule to calculate P(Y|X=x). Usually P(X|Y) can be related to the probability of generating the data given the model.(P(Y|X) = \(\frac{P(X|Y)P(Y)}{P(X)}\)) Example: Mixtures of Gaussians Discriminative Models Directly assume some functional form for P(Y|X) Estimate P(Y|X) directly from training data. There is a good saying for discriminative models: discriminative models don’t do anything more than they are asked to do. Examples: SVM, Logistic Regression, Neural Network Model SelectionIn order to choose the best model, we need to do model selection. If we have plentiful data, then one approach is to use some of the data to train some models, and then to compare them on independent data(validation set) and select the one having the best performance. What if the supply of data is limited? We know that, in order to build good models, we wish to use as much of the available data as possible. So in this situation, we need to use K-fold cross-validation: Divide the dataset into K groups Take one group as test set, the others as training set. Repeat the last step, but this time choose another group as the test set. Repeat like step 3 until all groups are used for test set. calculate the average performance tested from the above test sets. choose the best one Drwabacks:The number of training runs in cross-validation is K times comparing with no cross-validation. This can be problematic for models in which the training costs a lot of time. The Curse of DimensionalityIf the dimension of the data is too high, we will meet the following problems: The complexity of the models will increase as the dimensionality of the dataset increases. Our geometric intuitions can fail badly when we consider spaces of higher dimensionality. In spaces of high dimensionality, most of the volume of a sphere is concentrated in a thin shell near the surface. Reference Book: Pattern Recognition and Machine Learning by Christopher Bishop notes of machine learning by Andrew Ng in cousera GPCA(Generalized Principle Component Analysis) by Yi Ma (to be published) 龙星计划2010 slides by Eric Xing 机器学习 周志华]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Markdown中插入数学公式]]></title>
    <url>%2F2015%2F09%2F25%2FMathTest%2F</url>
    <content type="text"><![CDATA[关于如何在hexo中插入数学公式，在网上找了一些方法，这里列出两个我觉得比较好的方法。 使用mathjax引擎这是一种比较简单的方法，直接在markdown中插入 1&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt; 即可，不需要额外的配置，方便快捷。还有一个很大的好处就是在macdown中打入公式后，在macdown的右侧会渲染出相应的公式，便于查看。但是在hexo d到github后，这种方法响应的时间比较长，所以最好的办法是，在macdown中编辑的时候用这种方法，用hexo d上传的时候用下面的方法。 以下是几个相应的例子和代码： 行间公式： $$A_1 = 5 $$ $$\frac{a}{b}$$ $$x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}$$ 行内公式： \(x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}\) 行间公式代码： 12345$$A_1 = 5 $$$$\frac&#123;a&#125;&#123;b&#125;$$$$x=\frac&#123;-b\pm\sqrt&#123;b^2-4ac&#125;&#125;&#123;2a&#125;$$ 行内公式代码： 1\\(x=\frac&#123;-b\pm\sqrt&#123;b^2-4ac&#125;&#125;&#123;2a&#125;\\) 对主题的after_footer.ejs作修改具体流程请参见在 Hexo 中完美使用 Mathjax 输出数学公式 值得注意的是，使用这种方法不能在编辑macdown公式的时候实时进行查看，需要上传之后才可以看到相应的效果。还有这篇blog中提到的安装hexo math插件的方法，在mac上我没有成功设置成功，找不到相应的hexo math install指令。 薛定谔公式： $$ i\hbar\frac{\partial \psi}{\partial t}= \frac{-\hbar^2}{2m} \left(\frac{\partial^2}{\partial x^2}+ \frac{\partial^2}{\partial y^2}+ \frac{\partial^2}{\partial z^2}\right) \psi + V \psi.$$ Reference在 Hexo 中完美使用 Mathjax 输出数学公式 Hexo上使用MathJax来实现数学公式的表达 PSHexo中代码显示的效果还是不错的，以python快排为例： 12345678910class Solution(object): """docstring for Solution""" def quick_sort(self,num): if len(num) &lt;= 1: return num pivot = num[len(num)/2] left = [i for i in num if i &lt; pivot] middle = [i for i in num if i ==pivot] right = [j for j in num if j &gt; pivot] return self.quick_sort(left) + middle + self.quick_sort(right) 用macdown书写markdown，体验很不错。]]></content>
      <categories>
        <category>Mathjar</category>
      </categories>
      <tags>
        <tag>Mathjar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Tutorial]]></title>
    <url>%2F2015%2F09%2F24%2FHexoTutorial%2F</url>
    <content type="text"><![CDATA[Hexo——Mac安装教程在mac上搭建我的hexo博客还是折腾了一小会的，在这里写下这篇教程好让后人乘凉。 环境准备安装hexo需要先安装git和node.js，按照网上找的教程，在命令行里面进行安装，这样子安装会遇到很多error，需要改一些路径，很麻烦，我就是在这个地方消耗了很多时间。 推荐的安装方法就是去node.js和git的官网，下载mac对应的安装包，安装完成即可，无需做改动，方便迅速。 传送门： node.js官网 git官网 这里需要提到的一点是，对下载好的node.js安装包进行安装的时候，同时会安装好npm。如果是在命令行模式下安装npm的话，会遇到很多问题，比较耗时，也比较让人烦。 安装Hexo这里可以用node -v 和 git –version 来查看node.js和git是否已经安装好。 如果上面的应用程序都安装好了的话，就可以准备安装Hexo了。 $ npm install -g hexo-cli 安装Hexo完成后，执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 $ hexo init &lt;folder&gt; // hexo init ~/Hexo $ cd &lt;folder&gt; //cd Hexo/ $ npm install 这里需要注意的是不要忘记cd到你指定的文件夹下，不要忘记 npm install. 小试牛刀以上都安装好后，cd到安装Hexo的文件夹，输入 $ hexo g $ hexo s 然后在浏览器中打开http://0.0.0.0:4000/这个链接，就能看到你的博客了。 遇到的问题在调用hexo d上传的时候，会遇到ERROR Deployer not found: git的问题， 解决方法：npm install hexo-deployer-git –save即可。 友情链接Hexo官方文档]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
